<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,Meta Learning,Object Detection," />




  


  <link rel="alternate" href="/atom.xml" title="Sen Yang" type="application/atom+xml" />






<meta name="description" content="NeuIPS 2018 &gt; 原创博文 转载请注明https:&#x2F;&#x2F;yangsenius.github.io&#x2F;blog&#x2F;MetaAnchor&#x2F; 一般目标检测方法中的Anchors的生成是来自于人类的先验知识:\(b_i\in \mathcal{B} \ which \ is \ predefined \ by \ human\)（\(\mathcal{B}\)属于 \({prior}\) \(i">
<meta property="og:type" content="article">
<meta property="og:title" content="MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读">
<meta property="og:url" content="http://senyang-ml.github.io/2018/12/20/metaanchor/index.html">
<meta property="og:site_name" content="Sen Yang">
<meta property="og:description" content="NeuIPS 2018 &gt; 原创博文 转载请注明https:&#x2F;&#x2F;yangsenius.github.io&#x2F;blog&#x2F;MetaAnchor&#x2F; 一般目标检测方法中的Anchors的生成是来自于人类的先验知识:\(b_i\in \mathcal{B} \ which \ is \ predefined \ by \ human\)（\(\mathcal{B}\)属于 \({prior}\) \(i">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2018121317400085.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20181214193114742.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2018-12-20T01:52:16.000Z">
<meta property="article:modified_time" content="2020-03-13T10:59:41.000Z">
<meta property="article:author" content="yangsenius">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Meta Learning">
<meta property="article:tag" content="Object Detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/2018121317400085.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":2},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://senyang-ml.github.io/2018/12/20/metaanchor/"/>





  <title>MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读 | Sen Yang</title>
  








<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Sen Yang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-blogs">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Blogs
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/research/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://senyang-ml.github.io/2018/12/20/metaanchor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="yangsenius">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sen Yang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读</h1>
        

        <div class="post-meta">
                  

          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">posted on</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-20T09:52:16+08:00">
                2018-12-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          
             <span id="/2018/12/20/metaanchor/" class="leancloud_visitors" data-flag-title="MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><a href="http://papers.nips.cc/paper/7315-metaanchor-learning-to-detect-objects-with-customized-anchors" target="_blank" rel="noopener">NeuIPS 2018</a> &gt; 原创博文 转载请注明<a href="https://yangsenius.github.io/blog/MetaAnchor/" target="_blank" rel="noopener" class="uri">https://yangsenius.github.io/blog/MetaAnchor/</a></p>
<p>一般目标检测方法中的Anchors的生成是来自于人类的先验知识:<span class="math inline">\(b_i\in \mathcal{B} \ which \ is \ predefined \ by \ human\)</span>（<span class="math inline">\(\mathcal{B}\)</span>属于 <span class="math inline">\({prior}\)</span> <span class="math inline">\(i\)</span>代表网格或锚点），即</p>
<ul>
<li>通过固定锚点，或者划分网格，生成一定形状和尺寸的Anchor Bboxes 来作为候选检测区域,提取对应位置的图像特征，</li>
</ul>
<p>先验往往代表设计人员在构思最初的朴素想法，来源于直觉，并把这种直觉融合在设计者的实现过程与代码中。 <a id="more"></a> 下面举两个例子。</p>
<h3 id="在faster-rcnn中">在Faster Rcnn中</h3>
<p>对输出的(W,H,d)维Conv map进行滑动遍历，每个滑窗输出一个特征向量WxH个d维的特征向量</p>
<p>根据根据感受野中心不变的原理，每个滑窗中心对应原图的anchor锚点或者说anchor bboxes的中心。</p>
<p>每个锚点映射到原图，实际上对应着来自3x3(3种特定的尺度x3个特定的形状)个的anchor boxes，我们认为这9个anchor bboxes经过特征提取得到的具有尺度不变性的特征向量，这些anchor bboxes意味着proposals。</p>
<p>然后作者使用先验规定：proposal与GTbbox iou大于某个阈值（0.7）认为是正样本，小于某个阈值（0.3）为负样本，其余的不参与训练！即给这些proposals做标签！</p>
<p>然后把这些正负样本送入RPN进行训练。</p>
<p>loss由regression和classification两个loss构成，即预测proposal的中心位置和宽高，以及proposal属于前景or背景</p>
<p>注意：这里的regression loss包含三个坐标：预测bbox、anchor bboxes、GT——bboxes,loss函数的目标是，缩小 [预测bbox与anchor bboxes相对偏移] 和[gt_bbox与anchor bboxes相对偏移]之间的差距！</p>
<p>经过RPN筛选后的Proposal的特征图的尺寸大小是不一致的，经过ROIPOOling得到特征维度一致的特征，使用与RPN共享卷积的Fast Rcnn进行进一步的分类和回归。</p>
<h3 id="在yolo中">在yolo中</h3>
<p>对任意输入尺寸的图像划分为<span class="math inline">\(s*s\)</span>个网格</p>
<p>每个网格预测B个bbox的4个位置和1个置信度 - (confidence代表了所预测的box中含有object的置信度和这个box预测的有多准两重信息,object落在一个grid cell里，第一项取1，否则取0。 第二项是预测的bounding box和实际的groundtruth之间的IoU值)</p>
<p>每个网格同时预测C个类的类别信息(每个网格属于的某类别的条件概率)</p>
<p>即对于一个输入图像，其输出的张量为 <span class="math inline">\(S*S*（B*5+C）\)</span></p>
<h2 id="在这里有必要说明这里anchor先验的含义即要把anchor的设计位置尺寸类比蕴含在anchor-function的设计中而不能成为一个独立的模块">在这里，有必要说明，这里“Anchor先验”的含义，即：要把anchor的设计（位置、尺寸、类比）蕴含在anchor function的设计中，而不能成为一个独立的模块</h2>
<h4 id="作者总结了一个较为一般的形式">作者总结了一个较为一般的形式：</h4>
<p><span class="math display">\[\mathcal{F}_{b_i}(\mathbf{x};\theta_i)=\left(\mathcal{F}^{cls}_{b_i}(\mathbf{x};\theta^{cls}_i),\mathcal{F}^{reg}_{b_i}(\mathbf{x}; \theta^{reg}_i)\right)\]</span></p>
<p>判断： 1. 每个候选区域的与真实bbox（如果有）的相对位置 <span class="math inline">\(\mathcal{F}^{reg}_{b_i}(\mathord{\cdot})\)</span> 2. 每个候选区域的类别置信概率 <span class="math inline">\(\mathcal{F}^{cls}_{b_i}(\mathord{\cdot})\)</span></p>
<p>本篇文章，作者使用的Anchor Function 是从先验的<span class="math inline">\(b_i\)</span>动态生成的,通过如下函数：</p>
<p><span class="math display">\[\mathcal{F}_{b_i}=\mathcal{G}\left(b_i; w \right)(2)\]</span></p>
<blockquote>
<p><span class="math inline">\(\mathcal{G}(\mathord{\cdot})\)</span> is called <span class="math inline">\({anchor \ function \ generator}\)</span> which maps any bounding box prior <span class="math inline">\(b_i\)</span> to the corresponding anchor function <span class="math inline">\(\mathcal{F}_{b_i}\)</span>; and <span class="math inline">\(w\)</span> represents the parameters. Note that in MetaAnchor the prior set <span class="math inline">\(\mathcal{B}\)</span> is not necessarily predefined; instead, it works as a  manner -- during inference, users could specify any anchor boxes, generate the corresponding anchor functions and use the latter to predict object boxes.</p>
</blockquote>
<p>上面是作者的原话，我觉得这个想法还是非常具有启发性的。我的理解是：</p>
<p>我们不是先盲目地生成大量的Anchor来判断是否抛弃，而是根据后面<strong>推理时</strong>的需要，在对应的位置生成特定的anchor boxes，然后生成anchor function来预测物体bbox，这样就避免了大量无关的候选框？这是我的理解，不知道对不对，接着读论文~</p>
<ul>
<li><p>“default boxes” , “priors” or “grid cells” 经常作为一个默认的方法。很多任务需要你在设计achor的大小、尺寸、位置时需要小心谨慎，不同数据集之间的物体bbox分布也会影响anchor的选择，但是MetaAnchor的方法就不用考虑这个问题。</p></li>
<li><p>受到 Learning to learn、few shot learning 、transfer learning的启发：有时候，我们的权重预测不是通过模型本身来学习，而是通过另一个结构（模型）来取预测权重，比如（Learning to learn by gradient descent by gradient descent，hypernetworks等），作者还拿自己的方法和learning to segment everything 作了对比，作者的权重预测是为了生成anchor function。</p></li>
</ul>
<p>仿佛，论文最关键的就是如何生成anchor function了，也就是这个函数了：</p>
<p><span class="math display">\[\mathcal{F}_{b_i}=\mathcal{G}\left(b_i; w \right)\]</span></p>
<p>下面详细讨论这个机制。</p>
<h2 id="anchor-function-generator">Anchor Function Generator</h2>
<blockquote>
<p>In MetaAnchor framework, <span class="math inline">\({anchor \ function}\)</span> is dynamically generated from the customized box prior (or anchor box) <span class="math inline">\(b_i\)</span> rather than fixed function associated with predefined anchor box. So, <span class="math inline">\({anchor \ function \ generator}\)</span> <span class="math inline">\(\mathcal{G}(\mathord{\cdot})\)</span> (see Equ.2), which maps <span class="math inline">\(b_i\)</span> to the corresponding anchor function <span class="math inline">\(\mathcal{F}_{b_i}\)</span>, plays a key role in the framework.</p>
</blockquote>
<p>作者强调了从<span class="math inline">\(b_i\)</span>映射到anchor function <span class="math inline">\(\mathcal{F}_{b_i}\)</span>, 这种映射关系是因为<span class="math inline">\(b_i\)</span>是带着一种随机性</p>
<blockquote>
<p>In order to model <span class="math inline">\(\mathcal{G}(\mathord{\cdot})\)</span> with neural work, inspired by <a href>HyperNetworks</a>,<a href>Learning to segment everything</a>, first we assume that for different <span class="math inline">\(b_i\)</span> anchor functions <span class="math inline">\(\mathcal{F}_{b_i}\)</span> share the same formulation <span class="math inline">\(\mathcal{F}(\mathord{\cdot})\)</span> but have different parameters, which means:</p>
</blockquote>
<p><span class="math display">\[\mathcal{F}_{b_i}(\mathbf{x}; \theta_i) = \mathcal{F}(\mathbf{x}; \theta_{b_i})\]</span></p>
<p>作者写这个公式，似乎想给出 无论怎样选择<span class="math inline">\(b_i\)</span> 的anchor function的一般形式。为什么这么做呢？下标的变换有什么意义吗？</p>
<p>我根据后面的内容，猜测：一般anchor function在设计时是要考虑 anchor<span class="math inline">\(b_i\)</span>的预定义方式，也就是我们要根据不同的anchor先验，具体设计出相对应的anchor function。如果我们anchor function的设计能够独立于anchor<span class="math inline">\(b_i\)</span>的预定义方式，让anchor<span class="math inline">\(b_i\)</span>的设计变成一个函数的可学习的参数形式，那么就把问题转化为一般的超参数学习，或者Meta-learning 的方式。之前我研究Learning to learn by gradient descent by gradient descent，作者就是让人工干预设计的优化方式，变成了可以学习的参数，二者虽然面对的问题的不一样，但是都包含了一个共同的思想：</p>
<p>让人工设计的先验知识，转化成，可以通过另一个结构或模型学习的，参数形式：</p>
<p><strong><span class="math display">\[人工先验知识 \rightarrow  可学习的参数形式\]</span></strong></p>
<p>这个思想和我上一篇<a href="https://blog.csdn.net/senius/article/details/84483329" target="_blank" rel="noopener">博客:learning to learn</a> 所涉及的方法，在理念上不谋而合</p>
<p>接着看论文。</p>
<p>论文说道： &gt; each anchor function is distinguished only by its parameters <span class="math inline">\(\theta_{b_i}\)</span>, anchor function generator could be formulated to predict <span class="math inline">\(\theta_{b_i}\)</span> as follows:</p>
<p><span class="math display">\[\theta_{b_i} = \mathcal{G}(b_i; w) \\= \theta^* + \mathcal{R}(b_i; w)\]</span></p>
<p>就是说，每个anchor function 通过参数 <span class="math inline">\(\theta_{b_i}\)</span> 来唯一确定(我的理解应该没错)，其中<span class="math inline">\(\theta^*\)</span>代表共享参数（独立于<span class="math inline">\({b_i}\)</span>，并且可以学习），残差项<span class="math inline">\(\mathcal{R}(b_i; w)\)</span>依赖于 anchor bbox <span class="math inline">\({b_i}\)</span></p>
<p>然后<span class="math inline">\(\mathcal{R}(b_i; w)\)</span>使用一个简单的两层全连接网络来表示：</p>
<p><span class="math display">\[\mathcal{R}(b_i, w) = \mathrm{W}_2 \sigma \left( \mathrm{W}_1 b_i \right)\]</span></p>
<p>作者还考虑把图像特征引入到参数 <span class="math inline">\(\theta_{b_i}\)</span>的学习中：</p>
<p><span class="math display">\[\theta_{b_i} = \mathcal{G}(b_i; \mathbf{x}, w) \\
    = \theta^* + \mathrm{W}_2 \sigma \left(
    \mathrm{W}_{11} b_i + \mathrm{W}_{12} r(\mathbf{x})
    \right)\]</span></p>
<p><span class="math inline">\(r(\mathord{\cdot})\)</span> 用来给 <span class="math inline">\(\mathbf{x}\)</span>降维;</p>
<p>以上就是论文的理论思想了！</p>
<figure>
<img src="https://img-blog.csdnimg.cn/2018121317400085.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<h2 id="具体实施细节结合retinanet代码让我们来感受什么是prior什么是meta">具体实施细节，结合RetinaNet代码，让我们来感受什么是“Prior”？什么是“Meta”</h2>
<blockquote>
<p>作者没有公布自己的源码是一件令人头疼的事情，这样就不知道，作者是如何把可学习的参数<span class="math inline">\(\theta_{b_i}\)</span>如何融进anchor function，不过我后面会试图写一下。</p>
</blockquote>
<p>作者说，这个方法更实用于one-stage的检测方法如 RetinaNet，yolo等，two-stage方法精度似乎受到第二阶段（anchor 不再发挥作用）的学习的影响更大。</p>
<p>作者主要说明了MetaAnchor在RetinaNet上的使用，先来看看什么是RetianNet，放上一段简介的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RetinaNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    num_anchors = <span class="number">9</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes=<span class="number">20</span>)</span>:</span></span><br><span class="line">        super(RetinaNet, self).__init__()</span><br><span class="line">        self.fpn = FPN50()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.reg_head = self._make_head(self.num_anchors*<span class="number">4</span>)</span><br><span class="line">        self.cls_head = self._make_head(self.num_anchors*self.num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        fms = self.fpn(x)</span><br><span class="line">        reg_preds = []</span><br><span class="line">        cls_preds = []</span><br><span class="line">        <span class="keyword">for</span> fm <span class="keyword">in</span> fms:</span><br><span class="line">            loc_pred = self.loc_head(fm)</span><br><span class="line">            cls_pred = self.cls_head(fm)</span><br><span class="line">            loc_pred = loc_pred.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous().view(x.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>)                 <span class="comment"># [N, 9*4,H,W] -&gt; [N,H,W, 9*4] -&gt; [N,H*W*9, 4]</span></span><br><span class="line">            cls_pred = cls_pred.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous().view(x.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes)  <span class="comment"># [N,9*20,H,W] -&gt; [N,H,W,9*20] -&gt; [N,H*W*9,20]</span></span><br><span class="line">            loc_preds.append(loc_pred)</span><br><span class="line">            cls_preds.append(cls_pred)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(loc_preds,<span class="number">1</span>), torch.cat(cls_preds,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_head</span><span class="params">(self, out_planes)</span>:</span></span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            layers.append(nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>))</span><br><span class="line">            layers.append(nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layers.append(nn.Conv2d(<span class="number">256</span>, out_planes, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>))</span><br><span class="line"><span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注： 以上代码来自于<a href="https://github.com/kuangliu/pytorch-retinanet/blob/master/retinanet.py" target="_blank" rel="noopener">kuangliu/pytorch-retinanet</a></p>
</blockquote>
<p>从以上代码</p>
<p>_make_head（self, out_planes)</p>
<p>函数中可以得知：我们必须把anchor的数量考虑并体现在RetinaNet最后一层卷积核的通道数量上。 那么作为RetinaNET网络结构的这个卷积核部分，就包含了我先验的一种设计（Anchor类型数为9）。</p>
<p>这样做的弊端就是：假如我换了anchor的种类或数量，那么就要重新改变这个卷积核的设计，进而影响了网络的结构和参数学习，那么这就意味着我先前学习的对于9个Anchor的RetinaNet不再具有一般性，不再具备迁移学习的能力。</p>
<p>如果我想，换一种数据集bbox的分布，或者换一种先验anchor的选择方式，网络依旧能够使用的话，就必须将anchor的先验从原来的设计中剥离出来作为一个独立的结构，从而不影响整体结构的设计，并且可以根据需求自定义不同的anchor设计，这也就是这篇论文要解决的问题，并冠以“MetaAnchor”的称号，并使用了一个<span class="math inline">\(\mathcal{G}(b_i; w)\)</span>的anchor function generator</p>
<p>在RetianNet 的原设计中，每个detection head模块最后一层，对于预定义的3x3中anchor bboxes ，anchor function中：</p>
<ul>
<li>cls模块用3x3x80（类别）=720个通道卷积核，生成720维的预测向量</li>
<li>reg模块有3x3x4=36个通道卷积核，生成36维的预测向量</li>
</ul>
<p>而在使用MetaAnchor后，就降成了：</p>
<ul>
<li>cls模块有80（类别）=80个通道卷积核，生成80维的预测向量</li>
<li>reg模块有4个通道卷积核，生成4维的预测向量</li>
</ul>
<p>这就就需要重新设计anchor function。根据自己定制（customized）的anchor bbox<span class="math inline">\({b_i}\)</span>首先，应该考虑如何编码<span class="math inline">\({b_i}\)</span>，它包含了位置、尺寸、类别信息，多亏了RetianNet的全卷积结构，位置坐标信息已经包含在Feature map 中，我们使用<span class="math inline">\(\mathcal{G}(\cdot)\)</span>来预测类别，那么<span class="math inline">\({b_i}\)</span>只需要包含尺寸信息：</p>
<p><span class="math display">\[b_i = \left(\log \frac{ah_i}{AH}, \log \frac{aw_i}{AW} \right)\]</span></p>
<p>在一个训练的mini-batch中，我们给定一个二维<span class="math inline">\(b_i\)</span>的数值，分别经过两层的全连接网络<span class="math inline">\(\mathcal{G}(b_i; w_{cls})\)</span>和<span class="math inline">\(\mathcal{G}(b_i; w_{reg})\)</span>的映射，得到一个<span class="math inline">\(W_{cls}\)</span>和<span class="math inline">\(W_{reg}\)</span>维度的参数<span class="math inline">\(\theta_{cls,b_i}\)</span>和<span class="math inline">\(\theta_{reg,b_i}\)</span></p>
<p>论文里面没有给出这个参数<span class="math inline">\(\theta_{cls,b_i}\)</span>和<span class="math inline">\(\theta_{reg,b_i}\)</span>如何写入到Loss function中，我根据作者思路猜测：</p>
<p>论文提到 <span class="math inline">\(\mathcal{G} \left(b_i, w\right)\)</span> 是一个低秩的子空间</p>
<p>不过根据论文的权重预测的思想，这里的参数<span class="math inline">\(\theta_{cls,b_i}\)</span>和<span class="math inline">\(\theta_{reg,b_i}\)</span>应该在lossfunction中发挥权重的作用，在训练过程中，通过给定一个位置和尺度下的anchor bbox的输出和标签，乘以相应权重，来计算该anchor点对应的所有anchors总的loss:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Anchor_bbox_size</span><span class="params">(ah_i,aw_i,level)</span>:</span></span><br><span class="line">        minimum_size = <span class="number">20</span></span><br><span class="line">        AH,AW = minimum_size * np.pow(<span class="number">2</span>,level<span class="number">-1</span>)</span><br><span class="line">        b_i=(np.log(ah_i/AH),np.log(aw_i/AW))</span><br><span class="line">        <span class="keyword">return</span> b_i</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">anchor_bbox_generator</span><span class="params">(b_i,level=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">'''b_i = (log(ah_i/AH),log(aw_i/AW))</span></span><br><span class="line"><span class="string">       b_t = [N,2]     '''</span></span><br><span class="line">    </span><br><span class="line">    hidden_dim = <span class="number">5</span></span><br><span class="line">    theta_dim = <span class="number">10</span></span><br><span class="line">    theta_standard =torch.randn(theta_dim)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## two -layer</span></span><br><span class="line">    Residual_theta =F.linear( F.relu (F.linear(bi,(<span class="number">2</span>,hidden_dim))) , (hidden_dim,theta_dim ) )</span><br><span class="line">    </span><br><span class="line">    theta_b_i = theta_standard + Residual_theta</span><br><span class="line">    </span><br><span class="line">    reutrn theta_b_i</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RetinaNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes=<span class="number">20</span>)</span>:</span></span><br><span class="line">        super(RetinaNet, self).__init__()</span><br><span class="line">        self.fpn = FPN50()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.reg_head = self._make_head(<span class="number">4</span>)</span><br><span class="line">        self.cls_head = self._make_head(self.num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        fms = self.fpn(x)</span><br><span class="line">        reg_preds = []</span><br><span class="line">        cls_preds = []</span><br><span class="line">        <span class="keyword">for</span> fm <span class="keyword">in</span> fms:</span><br><span class="line">            loc_pred = self.loc_head(fm)</span><br><span class="line">            cls_pred = self.cls_head(fm)</span><br><span class="line">            loc_pred = loc_pred.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous().view(x.size(<span class="number">0</span>),<span class="number">-1</span>,<span class="number">4</span>)            <span class="comment"># [N, 4,H,W] -&gt; [N,H,W, 4] -&gt; [N,H*W, 4]</span></span><br><span class="line">            cls_pred = cls_pred.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous().view(x.size(<span class="number">0</span>),<span class="number">-1</span>,self.num_classes)  <span class="comment"># [N,20,H,W] -&gt; [N,H,W,20] -&gt; [N,H*W,20]</span></span><br><span class="line">            loc_preds.append(loc_pred)</span><br><span class="line">            cls_preds.append(cls_pred)</span><br><span class="line">        <span class="keyword">return</span> torch.cat(loc_preds,<span class="number">1</span>), torch.cat(cls_preds,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_head</span><span class="params">(self, out_planes)</span>:</span></span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            layers.append(nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>))</span><br><span class="line">            layers.append(nn.ReLU(<span class="literal">True</span>))</span><br><span class="line">        layers.append(nn.Conv2d(<span class="number">256</span>, out_planes, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>))</span><br><span class="line"><span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">focal_loss_meta</span><span class="params">(bi,cls_pred,cls_label,reg_pred,reg_label)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    bi = [N,2]</span></span><br><span class="line"><span class="string">    cls_pred = [N,20]</span></span><br><span class="line"><span class="string">    cls_label = [N,]</span></span><br><span class="line"><span class="string">    reg_pred = [N,4]</span></span><br><span class="line"><span class="string">    reg_label = [N,4]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    </span><br><span class="line">   </span><br><span class="line">    alpha = <span class="number">0.25</span></span><br><span class="line">    gamma = <span class="number">2</span></span><br><span class="line">    num_classes = <span class="number">20</span></span><br><span class="line">    </span><br><span class="line">    t = torch.eye（num_classes+<span class="number">1</span>）(cls_label, ）  <span class="comment"># [N,21] 20+背景 </span></span><br><span class="line">    <span class="comment"># t is one-hot vector</span></span><br><span class="line">    t = t[:,<span class="number">1</span>:]  <span class="comment"># 去掉 background 【N，20】 </span></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line">    p = F.logsigmoid(cls_pred)</span><br><span class="line">    pt = p*t + (<span class="number">1</span>-p)*(<span class="number">1</span>-t)         <span class="comment"># pt = p if t &gt; 0 else 1-p</span></span><br><span class="line">    m = alpha*t + (<span class="number">1</span>-alpha)*(<span class="number">1</span>-t)   </span><br><span class="line">    m = m * (<span class="number">1</span>-pt).pow(gamma)   <span class="comment"># focal loss 系数 解决样本不平衡</span></span><br><span class="line">    </span><br><span class="line">    weight = anchor_bbox_generator(bi,) <span class="comment"># [N,W] W维的θ参数，该怎么用？ 还是说这里W=1？？</span></span><br><span class="line">    </span><br><span class="line">    cls_loss = F.binary_cross_entropy_with_logits(x, t, m, size_average=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>以上代码仅代表个人对论文的局限理解</p>
<p>因为看不到论文的代码，目前我理解最模糊的就是这个θ参数如何与loss function相结合的地方了，还请网友多多交流，欢迎发表更多的见解~</p>
<p>以上基本就介绍了是论文最主要的想法：</p>
<ul>
<li>MetaAnchor对于anchor的设定和bbox的分布更加鲁棒</li>
<li>MetaAnchor可以缩减不同数据集bbox分布的差异的影响，即更具迁移学习的能力！</li>
</ul>
<p>论文的更多的实验细节，我会继续阅读并更新博客~</p>
<p>=========================================</p>
<p>上次博客中说道，我理解最模糊的就是这个θ参数如何与ancnhor 的 loss function相结合的地方了</p>
<p>我重新阅读了论文，作者提到了权重预测的主要受到<strong>HyperNetworks</strong>的启发,然后我找来这篇论文，刚读完摘要，就恍然大悟理解了MetaAnchor里预测权重的思想，即这个θ参数的内涵，<span class="math inline">\(\theta_{b_i}\)</span> 即 <span class="math inline">\(\mathcal{F}_{csl}\left(\cdot\right)\)</span> 和 <span class="math inline">\(\mathcal{F}_{reg}\left(\cdot\right)\)</span> 的中的参数，在RetinaNet中代表了最后一层卷积核的参数！</p>
<h4 id="原来我在这个点上理解困难的原因是头脑中少了hypernetworks的先验">原来我在这个点上理解困难的原因是头脑中少了“HyperNetworks”的先验！</h4>
<blockquote>
<p>看来很多情况下，我们理解的困难源于：少了某些“先验知识”</p>
</blockquote>
<p><a href="https://arxiv.org/abs/1609.09106" target="_blank" rel="noopener">HyperNetwork</a> (ICLR2017)</p>
<p>HyperNetwork是什么呢，简言之：</p>
<p><strong>用一个网络(A-HyperNetwork)生成另外另一个网络(B-主体网络)的权重</strong></p>
<p>听起来很神奇，因为我们一般对于网络B的学习，通常经过梯度下降法产生梯度来更新参数。而这个工作可以直接用另一个网络的输出来预测。这样做的好处就是，我们可以将巨大参数量的权重学习，转换为一个小网络的参数学习，并可以通过端到端梯度优化的方法学习！</p>
<p>这篇论文分析了LSTM和CNN使用HyperNetwork的方法和效果，结合我们主要论述的MetaAnchor，我来简要介绍一下Static HyperNetwork在CNN中的应用</p>
<h2 id="通过一个两层全连接的小网络用一个layer-embedding来预测表征cnn的卷积核参数值">通过一个两层全连接的小网络，用一个layer embedding来预测（表征）CNN的卷积核参数值</h2>
<p>对于一个深度的卷积神经网络，其参数主要由卷积核构成</p>
<p>每个卷积核有 <span class="math inline">\(N_{in} \times N_{out}\)</span> 个滤波器 每个滤波器有 <span class="math inline">\(f_{size} \times f_{size}\)</span>.</p>
<p>假设这些参数存在一个矩阵 <span class="math inline">\(K^j \in \mathbb{R}^{N_{in}f_{size} \times N_{out}f_{size}}\)</span> for each layer <span class="math inline">\(j = 1,..,D\)</span>, 其中 <span class="math inline">\(D\)</span> 是卷积网络的深度</p>
<p>对于每一层 <span class="math inline">\(j\)</span>, hypernetwork 接受一个 a layer embedding <span class="math inline">\(z^j \in \mathbb{R}^{N_{z}}\)</span> 作为输入，并预测 <span class="math inline">\(K^j\)</span>, 可以写成:</p>
<p><span class="math display">\[ {K^j} = g( {z^j} ),\forall j = 1,..., D\]</span></p>
<p><span class="math display">\[{K} \in \mathbb{R}^{ N_{in}f_{size} \times N_{out}f_{size}}, {z} \in \mathbb{R}^{N_z}\]</span></p>
<figure>
<img src="https://img-blog.csdnimg.cn/20181214193114742.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><figcaption>在这里插入图片描述</figcaption>
</figure>
<p>公式中，所有可学习的参数 <span class="math inline">\(W_i\)</span>, <span class="math inline">\(B_i\)</span>, <span class="math inline">\(W_{out}\)</span>, <span class="math inline">\(B_{out}\)</span> 对于所有 <span class="math inline">\(z^{j}\)</span>共享</p>
<p>在推理时, 模型仅仅将学习到的 the layer embeddings <span class="math inline">\(z^j\)</span> 来生成第 <span class="math inline">\(j\)</span> 层的卷积核权重参数</p>
<p>这就将可学习的参数量改变了:</p>
<p><span class="math display">\[D \times N_{in} \times f_{size} \times N_{out}\times f_{size}\]</span></p>
<p><span class="math display">\[\rightarrow\]</span></p>
<p><span class="math display">\[N_{z}\times D + d\times (N_z + 1)\times N_i + f_{size}\times N_{out}\times f_{size}\times (d+1)\]</span></p>
<h4 id="应用到metaanchor中theta_b_i即retinanet的最后一层卷积核的参数">应用到MetaAnchor中：<span class="math inline">\(\theta_{b_i}\)</span>即RetinaNet的最后一层卷积核的参数</h4>
<p>即，我们用自定义anchor设计<span class="math inline">\({b_i}\)</span>成二维向量，作为“layer embedding”，输入两层的网络，预测了RetinaNet的最后一层卷积核参数的残差，这样就降低了原RetinaNet的卷积核滤波器的数量，就像之前提到的。</p>
<p><strong>～～2019年6月25日更～～</strong> 最后，可能还需要再次提到<strong>关于<span class="math inline">\(\theta^*\)</span> 和<span class="math inline">\(\mathcal{R}(b_i; w)\)</span>这两项的理解</strong>：</p>
<p>公式提到： <span class="math display">\[\theta_{b_i} = \mathcal{G}(b_i; w) \\= \theta^* + \mathcal{R}(b_i; w)\]</span></p>
<p>我们想要学习的是<span class="math inline">\(\theta_{b_i}\)</span> ，它有两部分构成：<span class="math inline">\(\theta^*\)</span> 和<span class="math inline">\(\mathcal{R}(b_i; w)\)</span>，当进行学习的时候，梯度流到<span class="math inline">\(\theta_{b_i}\)</span> 节点，会产生<span class="math inline">\(\theta^*\)</span> 和<span class="math inline">\(\mathcal{R}(b_i; w)\)</span>的梯度：<span class="math inline">\(\nabla\theta^*\)</span> 和<span class="math inline">\(\nabla\mathcal{R}(b_i; w)\)</span>, 而<span class="math inline">\(\nabla\theta^*\)</span>可以直接用来更新<span class="math inline">\(\theta^*\)</span> ，但<span class="math inline">\(\nabla\mathcal{R}(b_i; w)\)</span>进一步通过HyperNetwork网络流到其参数<span class="math inline">\(\nabla w\)</span>上，然后更新HyperNetwork的参数<span class="math inline">\(w\)</span>。以上是进一步的分析了，如果有问题欢迎提出～</p>

      
    </div>
    
    
    

    

    

    
      <div>
        
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Author：</strong>
    yangsenius
  </li>
  <li class="post-copyright-link">
    <strong>Link：</strong>
    <a href="http://senyang-ml.github.io/2018/12/20/metaanchor/" title="MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读">http://senyang-ml.github.io/2018/12/20/metaanchor/</a>
  </li>
  <li class="post-copyright-license">
    <strong>License： </strong>
    Unless otherwise stated,  all blogs use the <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> protocol, please indicate the source
  </li>
</ul>


      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/Meta-Learning/" rel="tag"># Meta Learning</a>
          
            <a href="/tags/Object-Detection/" rel="tag"># Object Detection</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        
          <div class="wp_rating">
            <div id="wpac-rating"></div>
          </div>
        

        

        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/17/learning_to_learn/" rel="next" title="Learning to learn by gradient descent by gradient descent-PyTorch实践">
                <i class="fa fa-chevron-left"></i> Learning to learn by gradient descent by gradient descent-PyTorch实践
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/07/13/rethinking_human_pose/" rel="prev" title="Rethinking Human Pose Estimation  重新思考人体姿态估计">
                Rethinking Human Pose Estimation  重新思考人体姿态估计 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Toc
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">yangsenius</p>
              <p class="site-description motion-element" itemprop="description">Talk is not cheap</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:yangsenius@seu.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#在faster-rcnn中"><span class="nav-number">1.</span> <span class="nav-text">在Faster Rcnn中</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在yolo中"><span class="nav-number">2.</span> <span class="nav-text">在yolo中</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#在这里有必要说明这里anchor先验的含义即要把anchor的设计位置尺寸类比蕴含在anchor-function的设计中而不能成为一个独立的模块"><span class="nav-number"></span> <span class="nav-text">在这里，有必要说明，这里“Anchor先验”的含义，即：要把anchor的设计（位置、尺寸、类比）蕴含在anchor function的设计中，而不能成为一个独立的模块</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#作者总结了一个较为一般的形式"><span class="nav-number">0.1.</span> <span class="nav-text">作者总结了一个较为一般的形式：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#anchor-function-generator"><span class="nav-number"></span> <span class="nav-text">Anchor Function Generator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#具体实施细节结合retinanet代码让我们来感受什么是prior什么是meta"><span class="nav-number"></span> <span class="nav-text">具体实施细节，结合RetinaNet代码，让我们来感受什么是“Prior”？什么是“Meta”</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#原来我在这个点上理解困难的原因是头脑中少了hypernetworks的先验"><span class="nav-number">0.1.</span> <span class="nav-text">原来我在这个点上理解困难的原因是头脑中少了“HyperNetworks”的先验！</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过一个两层全连接的小网络用一个layer-embedding来预测表征cnn的卷积核参数值"><span class="nav-number"></span> <span class="nav-text">通过一个两层全连接的小网络，用一个layer embedding来预测（表征）CNN的卷积核参数值</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#应用到metaanchor中theta_b_i即retinanet的最后一层卷积核的参数"><span class="nav-number">0.1.</span> <span class="nav-text">应用到MetaAnchor中：\(\theta_{b_i}\)即RetinaNet的最后一层卷积核的参数</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yangsenius</span>

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  









  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three-waves.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  











<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
        
    
<!-- END LOCAL -->


    
      <script src="https://utteranc.es/client.js"
        repo="senyang-ml/Comments"
        issue-term="title"
        label="utt-comment"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>


      
    






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("", "");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
  <script src="https://www.gstatic.com/firebasejs/4.6.0/firebase.js"></script>
  <script src="https://www.gstatic.com/firebasejs/4.6.0/firebase-firestore.js"></script>
  
  <script>
    (function () {

      firebase.initializeApp({
        apiKey: '',
        projectId: ''
      })

      function getCount(doc, increaseCount) {
        //increaseCount will be false when not in article page

        return doc.get().then(function (d) {
          var count
          if (!d.exists) { //has no data, initialize count
            if (increaseCount) {
              doc.set({
                count: 1
              })
              count = 1
            }
            else {
              count = 0
            }
          }
          else { //has data
            count = d.data().count
            if (increaseCount) {
              if (!(window.localStorage && window.localStorage.getItem(title))) { //if first view this article
                doc.set({ //increase count
                  count: count + 1
                })
                count++
              }
            }
          }
          if (window.localStorage && increaseCount) { //mark as visited
            localStorage.setItem(title, true)
          }

          return count
        })
      }

      function appendCountTo(el) {
        return function (count) {
          $(el).append(
            $('<span>').addClass('post-visitors-count').append(
              $('<span>').addClass('post-meta-divider').text('|')
            ).append(
              $('<span>').addClass('post-meta-item-icon').append(
                $('<i>').addClass('fa fa-users')
              )
              ).append($('<span>').text('visitors ' + count))
          )
        }
      }

      var db = firebase.firestore()
      var articles = db.collection('articles')

      //https://hexo.io/zh-tw/docs/variables.html
      var isPost = 'MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读'.length > 0
      var isArchive = '' === 'true'
      var isCategory = ''.length > 0
      var isTag = ''.length > 0

      if (isPost) { //is article page
        var title = 'MetaAnchor - Learning to Detect Objects with Customized Anchors - 2018 NeurIPS 解读'
        var doc = articles.doc(title)

        getCount(doc, true).then(appendCountTo($('.post-meta')))
      }
      else if (!isArchive && !isCategory && !isTag) { //is index page
        var titles = [] //array to titles

        var postsstr = '' //if you have a better way to get titles of posts, please change it
        eval(postsstr)

        var promises = titles.map(function (title) {
          return articles.doc(title)
        }).map(function (doc) {
          return getCount(doc)
        })
        Promise.all(promises).then(function (counts) {
          var metas = $('.post-meta')
          counts.forEach(function (val, idx) {
            appendCountTo(metas[idx])(val)
          })
        })
      }
    })()
  </script>


  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  <script type="text/javascript">
  wpac_init = window.wpac_init || [];
  wpac_init.push({widget: 'Rating', id: ,
    el: 'wpac-rating',
    color: 'fc6423'
  });
  (function() {
    if ('WIDGETPACK_LOADED' in window) return;
    WIDGETPACK_LOADED = true;
    var mc = document.createElement('script');
    mc.type = 'text/javascript';
    mc.async = true;
    mc.src = '//embed.widgetpack.com/widget.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
  })();
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


      
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  

</body>
</html>
