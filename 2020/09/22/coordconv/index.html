<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,Reproduce,Neural Network," />




  


  <link rel="alternate" href="/atom.xml" title="Sen Yang" type="application/atom+xml" />






<meta name="description" content="CoordConv 的研究与分析 本文主要进行了如下的代码实验和分析：  数据集：构造由坐标生成的one-hot heatmap与数值坐标之间的数据集：遵循An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution的quarter split方式。 模型：利用神经网络加坐标嵌入（MLP+Coor">
<meta property="og:type" content="article">
<meta property="og:title" content="CoordConv - My Surprising Finding.">
<meta property="og:url" content="http://senyang-ml.github.io/2020/09/22/coordconv/index.html">
<meta property="og:site_name" content="Sen Yang">
<meta property="og:description" content="CoordConv 的研究与分析 本文主要进行了如下的代码实验和分析：  数据集：构造由坐标生成的one-hot heatmap与数值坐标之间的数据集：遵循An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution的quarter split方式。 模型：利用神经网络加坐标嵌入（MLP+Coor">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211840620.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211620495.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211705256.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922213013965.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211731117.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211755053.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211812693.png">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/output.gif">
<meta property="og:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200924145925184.png">
<meta property="article:published_time" content="2020-09-22T11:53:41.000Z">
<meta property="article:modified_time" content="2020-09-24T07:04:32.044Z">
<meta property="article:author" content="杨森 &amp; yangsenius">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Reproduce">
<meta property="article:tag" content="Neural Network">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://senyang-ml.github.io/2020/09/22/coordconv/image-20200922211840620.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":2},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://senyang-ml.github.io/2020/09/22/coordconv/"/>





  <title>CoordConv - My Surprising Finding. | Sen Yang</title>
  








<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Sen Yang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">杨森</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-blogs">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Blogs
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/research/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://senyang-ml.github.io/2020/09/22/coordconv/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="杨森 & yangsenius">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sen Yang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CoordConv - My Surprising Finding.</h1>
        

        <div class="post-meta">
                  

          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">posted on</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-09-22T19:53:41+08:00">
                2020-09-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="coordconv-的研究与分析">CoordConv 的研究与分析</h1>
<p>本文主要进行了如下的代码实验和分析：</p>
<ul>
<li><p>数据集：构造由坐标生成的one-hot heatmap与数值坐标之间的数据集：遵循<a href="https://arxiv.org/abs/1807.03247" target="_blank" rel="noopener">An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution</a>的<em>quarter split</em>方式。</p></li>
<li><p>模型：利用神经网络加坐标嵌入（MLP+Coord and Conv+Coord）的方式进行拟合与泛化测试。</p></li>
<li><p>效果分析与发现：用Pytorch复现验证了An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution中Superivised Coordinates Regression任务的CoordConv的泛化性能！</p></li>
</ul>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage.filters <span class="keyword">import</span> gaussian</span><br><span class="line"></span><br><span class="line">h=<span class="number">64</span></span><br><span class="line">w=<span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position</span><span class="params">(H, W, is_cuda=False)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> is_cuda:</span><br><span class="line">        loc_w = torch.linspace(<span class="number">-1.0</span>, <span class="number">1.0</span>, W).cuda().unsqueeze(<span class="number">0</span>).repeat(H, <span class="number">1</span>)</span><br><span class="line">        loc_h = torch.linspace(<span class="number">-1.0</span>, <span class="number">1.0</span>, H).cuda().unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, W)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loc_w = torch.linspace(<span class="number">-1.0</span>, <span class="number">1.0</span>, W).unsqueeze(<span class="number">0</span>).repeat(H, <span class="number">1</span>)</span><br><span class="line">        loc_h = torch.linspace(<span class="number">-1.0</span>, <span class="number">1.0</span>, H).unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, W)</span><br><span class="line">    loc = torch.cat([loc_w.unsqueeze(<span class="number">0</span>), loc_h.unsqueeze(<span class="number">0</span>)], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> loc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">heatmap_generator</span><span class="params">(torch.utils.data.Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size=<span class="params">(h, w)</span>, sigma=<span class="number">2</span>, num=<span class="number">1000</span>, is_train=True, uniform=False, seed=<span class="number">0</span>, coordadd=False)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dataset_size = num</span><br><span class="line">        self.heatmap_size = size</span><br><span class="line">        self.sigma = sigma</span><br><span class="line">        self.is_train = is_train</span><br><span class="line">        self.uniform = uniform</span><br><span class="line">        self.coordadd = coordadd</span><br><span class="line">        self.generator(seed, num)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(self,seed,num)</span>:</span></span><br><span class="line">        torch.manual_seed(seed)</span><br><span class="line">        np.random.seed(seed)</span><br><span class="line">        </span><br><span class="line">        self.db = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">            heatmap = np.zeros(shape=self.heatmap_size, dtype=np.float32)</span><br><span class="line">            <span class="keyword">if</span> self.uniform:</span><br><span class="line">                y = np.random.randint(self.heatmap_size[<span class="number">0</span>])</span><br><span class="line">                x = np.random.randint(self.heatmap_size[<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">elif</span> self.is_train:</span><br><span class="line">                <span class="keyword">if</span> np.random.rand() &lt; <span class="number">1</span>/<span class="number">3</span>:  <span class="comment"># 1/3 probability: fall in this area</span></span><br><span class="line">                    x = np.random.randint(<span class="number">0</span>,  self.heatmap_size[<span class="number">1</span>]/<span class="number">2</span>)</span><br><span class="line">                    y = np.random.randint(self.heatmap_size[<span class="number">0</span>]/<span class="number">2</span>, self.heatmap_size[<span class="number">0</span>])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    x = np.random.randint(self.heatmap_size[<span class="number">1</span>])</span><br><span class="line">                    y = np.random.randint(self.heatmap_size[<span class="number">0</span>]/<span class="number">2</span>)     </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                y = np.random.randint(self.heatmap_size[<span class="number">0</span>]/<span class="number">2</span>, self.heatmap_size[<span class="number">0</span>])</span><br><span class="line">                x = np.random.randint(self.heatmap_size[<span class="number">1</span>]/<span class="number">2</span>, self.heatmap_size[<span class="number">1</span>])</span><br><span class="line">                </span><br><span class="line">            heatmap[y,x] = <span class="number">1</span></span><br><span class="line"><span class="comment">#             heatmap = gaussian(heatmap, sigma=self.sigma)</span></span><br><span class="line"><span class="comment">#             heatmap /= np.amax(heatmap)</span></span><br><span class="line">            self.db.append(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">'heatmap'</span>:heatmap,</span><br><span class="line">                    <span class="string">'pos'</span>: [x,y]  <span class="comment">#[x/self.heatmap_size[1],y/self.heatmap_size[0]]</span></span><br><span class="line">                &#125;)</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self,)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.dataset_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        heatmap = self.db[idx][<span class="string">'heatmap'</span>]</span><br><span class="line">        heatmap = torch.as_tensor(heatmap, dtype=torch.float32)</span><br><span class="line">        pos = self.db[idx][<span class="string">'pos'</span>]</span><br><span class="line">        pos = torch.as_tensor(pos, dtype=torch.float32)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.coordadd:</span><br><span class="line">            loc = position(heatmap.size(<span class="number">0</span>), heatmap.size(<span class="number">1</span>))</span><br><span class="line">            heatmap = torch.cat([heatmap.unsqueeze(<span class="number">0</span>), loc], dim=<span class="number">0</span>) <span class="comment"># [3,h,w]</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> heatmap, pos</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x=heatmap_generator(num=<span class="number">2</span>, seed=<span class="number">0</span>, is_train=<span class="literal">True</span>, coordadd=<span class="literal">True</span>)</span><br><span class="line">d, _ = x[<span class="number">0</span>]</span><br><span class="line">d = d.numpy()</span><br><span class="line">print(d.shape)</span><br><span class="line">figs, axs = plt.subplots(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">axs.flat[<span class="number">0</span>].imshow(d[<span class="number">0</span>], cmap=<span class="string">'jet'</span>)</span><br><span class="line">axs.flat[<span class="number">1</span>].imshow(d[<span class="number">1</span>], cmap=<span class="string">'jet'</span>)</span><br><span class="line">axs.flat[<span class="number">2</span>].imshow(d[<span class="number">2</span>], cmap=<span class="string">'jet'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>(3, 64, 64)</code></pre>
<figure>
<img src="/2020/09/22/coordconv/image-20200922211840620.png" alt="image-20200922211840620"><figcaption>image-20200922211840620</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, h, output_dim)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.l = nn.Sequential(</span><br><span class="line">            nn.Linear(input_dim, h),</span><br><span class="line">            nn.LayerNorm(h),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(h, h),</span><br><span class="line">            nn.LayerNorm(h),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(h, output_dim),</span><br><span class="line">            </span><br><span class="line">        )</span><br><span class="line">       </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x.flatten(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.l(x).sigmoid()</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">convnet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, img_size, h, output_dim)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(<span class="number">3</span>,h,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        dim = img_size[<span class="number">0</span>]*img_size[<span class="number">1</span>]*h</span><br><span class="line">        self.l = nn.Sequential(</span><br><span class="line">            nn.Linear(dim, h),</span><br><span class="line">            nn.LayerNorm(h),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(h, h),</span><br><span class="line">            nn.LayerNorm(h),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(h, output_dim),</span><br><span class="line">            </span><br><span class="line">        )</span><br><span class="line">       </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.l(x).sigmoid()</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">'CUDA_VISIBLE_DEVICES'</span>] = <span class="string">"0,1"</span></span><br><span class="line">    </span><br><span class="line">train_set = heatmap_generator(num=<span class="number">2000</span>, seed=<span class="number">0</span>, is_train=<span class="literal">True</span>, coordadd=<span class="literal">True</span>)</span><br><span class="line">valid_set = heatmap_generator(num=<span class="number">500</span>, seed=<span class="number">1</span>, is_train=<span class="literal">False</span>, coordadd=<span class="literal">True</span>)</span><br><span class="line">test_set = heatmap_generator(num=<span class="number">1000</span>, seed=<span class="number">2</span>, is_train=<span class="literal">False</span>, coordadd=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">64</span>, drop_last=<span class="literal">False</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=<span class="number">64</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_set, batch_size=<span class="number">64</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">length = <span class="number">3</span>*h*w</span><br><span class="line">model = net(length, <span class="number">256</span>, <span class="number">2</span>).cuda()</span><br><span class="line">epochs = <span class="number">200</span></span><br><span class="line">criterion = nn.L1Loss(reduction=<span class="string">'mean'</span>).cuda()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">train_losses = []</span><br><span class="line">valid_losses = []</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    model.train()</span><br><span class="line">    t = <span class="number">0</span></span><br><span class="line">    n1 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> id, (heatmaps, coords) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        heatmaps, coords = heatmaps.cuda(), coords.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        out = model(heatmaps)</span><br><span class="line">        wh = torch.tensor([w,h]).unsqueeze(<span class="number">0</span>).to(out.device) </span><br><span class="line">        out = out*wh</span><br><span class="line">        coords[:,<span class="number">0</span>]  = coords[:,<span class="number">0</span>] * w</span><br><span class="line">        coords[:,<span class="number">1</span>]  = coords[:,<span class="number">1</span>] * h</span><br><span class="line">        </span><br><span class="line">        loss = criterion(out, coords)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        t +=loss.item()</span><br><span class="line">        n1 +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> id%<span class="number">5</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[&#123;&#125;/&#123;&#125;]:train loss:&#123;:.3f&#125;"</span>.format(e,id,loss.item()))</span><br><span class="line">            </span><br><span class="line">    train_losses.append(t/n1)</span><br><span class="line">    v = <span class="number">0</span></span><br><span class="line">    n2 = <span class="number">0</span></span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="keyword">for</span> id, (heatmaps, coords) <span class="keyword">in</span> enumerate(valid_loader):</span><br><span class="line">        heatmaps, coords = heatmaps.cuda(), coords.cuda()</span><br><span class="line">        out = model(heatmaps)</span><br><span class="line">        </span><br><span class="line">        wh = torch.tensor([w,h]).unsqueeze(<span class="number">0</span>).to(out.device)      </span><br><span class="line">        out = out*wh     </span><br><span class="line">        coords[:,<span class="number">0</span>]  = coords[:,<span class="number">0</span>] * w</span><br><span class="line">        coords[:,<span class="number">1</span>]  = coords[:,<span class="number">1</span>] * h</span><br><span class="line">        </span><br><span class="line">        loss = criterion(out, coords)</span><br><span class="line">        v +=loss.item()</span><br><span class="line">        n2 +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> id%<span class="number">5</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[&#123;&#125;/&#123;&#125;]:valid loss:&#123;:.3f&#125;"</span>.format(e,id,loss.item()))</span><br><span class="line">    </span><br><span class="line">    valid_losses.append(v/n2)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>/<span class="number">0</span>]:train loss:<span class="number">66.604</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">5</span>]:train loss:<span class="number">56.174</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">10</span>]:train loss:<span class="number">62.741</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">15</span>]:train loss:<span class="number">61.951</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">20</span>]:train loss:<span class="number">54.515</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">25</span>]:train loss:<span class="number">56.364</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">30</span>]:train loss:<span class="number">56.916</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">0</span>]:valid loss:<span class="number">85.686</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">5</span>]:valid loss:<span class="number">86.086</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">0</span>]:train loss:<span class="number">55.726</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">5</span>]:train loss:<span class="number">62.358</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">10</span>]:train loss:<span class="number">65.846</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">15</span>]:train loss:<span class="number">59.389</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">20</span>]:train loss:<span class="number">62.986</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">25</span>]:train loss:<span class="number">63.098</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">30</span>]:train loss:<span class="number">58.376</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">0</span>]:valid loss:<span class="number">93.375</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">5</span>]:valid loss:<span class="number">93.775</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">0</span>]:train loss:<span class="number">61.380</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">5</span>]:train loss:<span class="number">61.412</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">10</span>]:train loss:<span class="number">58.127</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">15</span>]:train loss:<span class="number">60.215</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">20</span>]:train loss:<span class="number">59.366</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">25</span>]:train loss:<span class="number">58.879</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">30</span>]:train loss:<span class="number">60.355</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">0</span>]:valid loss:<span class="number">91.508</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">5</span>]:valid loss:<span class="number">91.908</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">0</span>]:train loss:<span class="number">60.517</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">5</span>]:train loss:<span class="number">55.383</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">10</span>]:train loss:<span class="number">63.124</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">15</span>]:train loss:<span class="number">56.669</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">20</span>]:train loss:<span class="number">62.911</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">25</span>]:train loss:<span class="number">62.907</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">30</span>]:train loss:<span class="number">51.110</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">0</span>]:valid loss:<span class="number">87.514</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">5</span>]:valid loss:<span class="number">87.915</span></span><br><span class="line">[<span class="number">4</span>/<span class="number">0</span>]:train loss:<span class="number">54.624</span></span><br><span class="line">[<span class="number">4</span>/<span class="number">5</span>]:train loss:<span class="number">59.512</span></span><br><span class="line"></span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">.....</span><br><span class="line">[<span class="number">194</span>/<span class="number">20</span>]:train loss:<span class="number">13.425</span></span><br><span class="line">[<span class="number">194</span>/<span class="number">25</span>]:train loss:<span class="number">8.053</span></span><br><span class="line">[<span class="number">194</span>/<span class="number">30</span>]:train loss:<span class="number">19.025</span></span><br><span class="line">[<span class="number">194</span>/<span class="number">0</span>]:valid loss:<span class="number">77.454</span></span><br><span class="line">[<span class="number">194</span>/<span class="number">5</span>]:valid loss:<span class="number">76.766</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">0</span>]:train loss:<span class="number">28.187</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">5</span>]:train loss:<span class="number">19.203</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">10</span>]:train loss:<span class="number">9.961</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">15</span>]:train loss:<span class="number">8.364</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">20</span>]:train loss:<span class="number">17.076</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">25</span>]:train loss:<span class="number">20.528</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">30</span>]:train loss:<span class="number">8.590</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">0</span>]:valid loss:<span class="number">80.181</span></span><br><span class="line">[<span class="number">195</span>/<span class="number">5</span>]:valid loss:<span class="number">80.544</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">0</span>]:train loss:<span class="number">10.859</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">5</span>]:train loss:<span class="number">9.294</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">10</span>]:train loss:<span class="number">19.587</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">15</span>]:train loss:<span class="number">23.072</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">20</span>]:train loss:<span class="number">9.886</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">25</span>]:train loss:<span class="number">20.046</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">30</span>]:train loss:<span class="number">17.368</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">0</span>]:valid loss:<span class="number">98.249</span></span><br><span class="line">[<span class="number">196</span>/<span class="number">5</span>]:valid loss:<span class="number">98.891</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">0</span>]:train loss:<span class="number">17.661</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">5</span>]:train loss:<span class="number">16.903</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">10</span>]:train loss:<span class="number">16.224</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">15</span>]:train loss:<span class="number">14.529</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">20</span>]:train loss:<span class="number">12.648</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">25</span>]:train loss:<span class="number">16.197</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">30</span>]:train loss:<span class="number">20.337</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">0</span>]:valid loss:<span class="number">89.428</span></span><br><span class="line">[<span class="number">197</span>/<span class="number">5</span>]:valid loss:<span class="number">90.051</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">0</span>]:train loss:<span class="number">8.844</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">5</span>]:train loss:<span class="number">8.096</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">10</span>]:train loss:<span class="number">5.853</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">15</span>]:train loss:<span class="number">12.344</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">20</span>]:train loss:<span class="number">7.346</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">25</span>]:train loss:<span class="number">14.299</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">30</span>]:train loss:<span class="number">20.001</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">0</span>]:valid loss:<span class="number">65.037</span></span><br><span class="line">[<span class="number">198</span>/<span class="number">5</span>]:valid loss:<span class="number">64.701</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">0</span>]:train loss:<span class="number">13.411</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">5</span>]:train loss:<span class="number">14.213</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">10</span>]:train loss:<span class="number">10.256</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">15</span>]:train loss:<span class="number">17.550</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">20</span>]:train loss:<span class="number">19.302</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">25</span>]:train loss:<span class="number">14.925</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">30</span>]:train loss:<span class="number">14.372</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">0</span>]:valid loss:<span class="number">74.663</span></span><br><span class="line">[<span class="number">199</span>/<span class="number">5</span>]:valid loss:<span class="number">75.049</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">mpl.style.use(<span class="string">'seaborn-bright'</span>)</span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">epochnum = list(range(<span class="number">0</span>,len(train_losses)))</span><br><span class="line"></span><br><span class="line">plt.plot(epochnum, train_losses, color=<span class="string">'black'</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.plot(epochnum, valid_losses, color=<span class="string">'red'</span>,linewidth=<span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>, fontdict=&#123;<span class="string">'family'</span>:<span class="string">'Arial'</span>&#125;)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>,fontdict=&#123;<span class="string">'family'</span>:<span class="string">'Arial'</span>&#125;)</span><br><span class="line">plt.xlim(<span class="number">0</span>, len(train_losses))</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">100</span>)</span><br><span class="line"><span class="comment">#plt.xticks(epochnum,100*list(epochnum) )</span></span><br><span class="line">plt.legend((<span class="string">'Train'</span>,</span><br><span class="line">            <span class="string">'Valid'</span>), loc=<span class="string">'best'</span>,fontsize=<span class="number">16</span>)</span><br><span class="line">plt.title(<span class="string">"generalization error with coordadd by CoordMLP"</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2020/09/22/coordconv/image-20200922211620495.png" alt="image-20200922211620495" style="zoom:50%;"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.cpu()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> id, (heatmaps, coords) <span class="keyword">in</span> enumerate(test_loader):</span><br><span class="line">        <span class="comment">#heatmaps, coords = heatmaps, coords.cuda()</span></span><br><span class="line">        out = model(heatmaps)</span><br><span class="line">        loss = criterion(out, coords)</span><br><span class="line">        <span class="keyword">if</span> id%<span class="number">5</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[&#123;&#125;/&#123;&#125;]:test loss:&#123;:.3f&#125;"</span>.format(e,id,loss.item()))</span><br></pre></td></tr></table></figure>
<pre><code>[199/0]:test loss:0.339
[199/5]:test loss:0.297
[199/10]:test loss:0.317
[199/15]:test loss:0.308</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">fig, ax1 = plt.subplots()</span><br><span class="line">fig2, ax2 = plt.subplots()</span><br><span class="line">print(model)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, p <span class="keyword">in</span> model.state_dict().items():</span><br><span class="line">    print(k)</span><br><span class="line">    <span class="comment">#print(p)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'weight'</span> <span class="keyword">in</span> k:</span><br><span class="line">        layer = k.split(<span class="string">'.'</span>)[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line">            <span class="comment">#</span></span><br><span class="line">            <span class="keyword">if</span> i.dim() &gt; <span class="number">0</span> :</span><br><span class="line">                <span class="keyword">for</span> z <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">                    ax1.scatter(layer, i[z].item(), s=<span class="number">1.5</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ax1.scatter(layer, i.item(), s=<span class="number">1.5</span>)</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">if</span> <span class="string">'bias'</span> <span class="keyword">in</span> k:</span><br><span class="line">        layer = k.split(<span class="string">'.'</span>)[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line">            <span class="comment">#</span></span><br><span class="line">            <span class="keyword">if</span> i.dim() &gt; <span class="number">0</span> :</span><br><span class="line">                <span class="keyword">for</span> z <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">                    ax2.scatter(layer, i[z].item(), s=<span class="number">1.5</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ax2.scatter(layer, i.item(), s=<span class="number">1.5</span>)</span><br><span class="line">    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">net(</span><br><span class="line">  (l): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">196608</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): LayerNorm((<span class="number">256</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): ReLU()</span><br><span class="line">    (<span class="number">3</span>): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): LayerNorm((<span class="number">256</span>,), eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): ReLU()</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">256</span>, out_features=<span class="number">2</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line">l<span class="number">.0</span>.weight</span><br><span class="line">l<span class="number">.0</span>.bias</span><br><span class="line">l<span class="number">.1</span>.weight</span><br><span class="line">l<span class="number">.1</span>.bias</span><br><span class="line">l<span class="number">.3</span>.weight</span><br><span class="line">l<span class="number">.3</span>.bias</span><br><span class="line">l<span class="number">.4</span>.weight</span><br><span class="line">l<span class="number">.4</span>.bias</span><br><span class="line">l<span class="number">.6</span>.weight</span><br><span class="line">l<span class="number">.6</span>.bias</span><br></pre></td></tr></table></figure>
<p><img src="/2020/09/22/coordconv/image-20200922211705256.png" alt="image-20200922211705256" style="zoom:50%;"></p>
<h2 id="可视化mlp的权重参数">可视化MLP的权重参数</h2>
<p>通过可视化MLP权重参数的取值，我们发现了不同层的取值范围的分布是不同的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">train_set = heatmap_generator(num=<span class="number">2000</span>, seed=<span class="number">0</span>, uniform=<span class="literal">True</span>)</span><br><span class="line">valid_set = heatmap_generator(num=<span class="number">500</span>, seed=<span class="number">1</span>, uniform=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> heatmap, pos <span class="keyword">in</span> train_set:</span><br><span class="line">    x = pos[<span class="number">0</span>]*w</span><br><span class="line">    y = pos[<span class="number">1</span>]*h</span><br><span class="line">    ax[<span class="number">0</span>].scatter(x, y, c=<span class="string">'red'</span>, s=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> heatmap, pos <span class="keyword">in</span> valid_set:</span><br><span class="line">    x = pos[<span class="number">0</span>]*w</span><br><span class="line">    y = pos[<span class="number">1</span>]*h</span><br><span class="line">    ax[<span class="number">0</span>].scatter(x, y, c=<span class="string">'blue'</span>, s=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.xlim(<span class="number">0</span>, w)</span><br><span class="line">plt.ylim(<span class="number">0</span>, h)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2020/09/22/coordconv/image-20200922213013965.png" alt="image-20200922213013965"><figcaption>image-20200922213013965</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">train_set = heatmap_generator(num=<span class="number">2000</span>, seed=<span class="number">0</span>, is_train=<span class="literal">True</span>, coordadd=<span class="literal">True</span>)</span><br><span class="line">valid_set = heatmap_generator(num=<span class="number">500</span>, seed=<span class="number">1</span>, is_train=<span class="literal">False</span>, coordadd=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">9</span>, <span class="number">4.5</span>), tight_layout=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> heatmap, pos <span class="keyword">in</span> train_set:</span><br><span class="line">    x = pos[<span class="number">0</span>]</span><br><span class="line">    y = pos[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">0</span>].scatter(x, y, c=<span class="string">'red'</span>, s=<span class="number">3</span>)</span><br><span class="line">    out = model(heatmap.flatten(<span class="number">0</span>).unsqueeze(<span class="number">0</span>).cuda()).squeeze().detach().cpu().numpy()</span><br><span class="line">    x = out[<span class="number">0</span>]</span><br><span class="line">    y = out[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">1</span>].scatter(x, y, c=<span class="string">'red'</span>, s=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> heatmap, pos <span class="keyword">in</span> valid_set:</span><br><span class="line">    x = pos[<span class="number">0</span>]</span><br><span class="line">    y = pos[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">0</span>].scatter(x, y, c=<span class="string">'blue'</span>, s=<span class="number">3</span>)</span><br><span class="line">    out = model(heatmap.flatten(<span class="number">0</span>).unsqueeze(<span class="number">0</span>).cuda()).squeeze().detach().cpu().numpy()</span><br><span class="line">    x = out[<span class="number">0</span>]</span><br><span class="line">    y = out[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">1</span>].scatter(x, y, c=<span class="string">'blue'</span>, s=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.xlim(<span class="number">0</span>, w)</span><br><span class="line">plt.ylim(<span class="number">0</span>, h)</span><br><span class="line">plt.title(<span class="string">"Unable to predict coords with coordadd by CoordMLP"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2020/09/22/coordconv/image-20200922211731117.png" alt="image-20200922211731117"><figcaption>image-20200922211731117</figcaption>
</figure>
<h2 id="coordmlp不具备预测坐标的泛化性能">CoordMLP不具备预测坐标的泛化性能</h2>
<p>把heatmap嵌入Coordinate Maps，然后Flatten，然后送进MLP中，模型可以在训练集上预测得很好，但是却不具备泛化能力。可以看到这种训练和验证集的划分方式还是非常有趣，并且是有难度的，它可以检测出模型预测坐标的泛化性能。</p>
<h1 id="coordconv-怎么样呢">CoordConv 怎么样呢？</h1>
<p>我用Pytorch复现了这个论文</p>
<p><a href="https://arxiv.org/abs/1807.03247" target="_blank" rel="noopener">An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution</a>论文提出了一种坐标嵌入的方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> coordconv <span class="keyword">import</span> CoordConv1d, CoordConv2d, CoordConv3d</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">convnet1</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(convnet1, self).__init__()</span><br><span class="line">        self.coordconv = CoordConv2d(<span class="number">1</span>, <span class="number">8</span>, <span class="number">1</span>, with_r=<span class="literal">True</span>)</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv4 = nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5 = nn.Conv2d(<span class="number">8</span>, <span class="number">2</span>, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=<span class="number">64</span>, stride=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        x = self.coordconv(x)</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = self.conv4(x)</span><br><span class="line">        x = self.conv5(x)</span><br><span class="line">        x = self.pool(x)  <span class="comment"># [bs, 2, 1, 1]</span></span><br><span class="line">        x = x.squeeze()</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">'CUDA_VISIBLE_DEVICES'</span>] = <span class="string">"0"</span></span><br><span class="line"></span><br><span class="line">train_set = heatmap_generator(num=<span class="number">2000</span>, seed=<span class="number">0</span>, is_train=<span class="literal">True</span>,) <span class="comment"># coordadd=True)</span></span><br><span class="line">valid_set = heatmap_generator(num=<span class="number">500</span>, seed=<span class="number">1</span>, is_train=<span class="literal">False</span>,) <span class="comment"># coordadd=True)</span></span><br><span class="line">test_set = heatmap_generator(num=<span class="number">1000</span>, seed=<span class="number">2</span>, is_train=<span class="literal">False</span>,) <span class="comment"># coordadd=True)</span></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">256</span>, drop_last=<span class="literal">False</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=<span class="number">32</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_set, batch_size=<span class="number">32</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">model = convnet1().cuda()</span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line">criterion = nn.MSELoss(reduction=<span class="string">'mean'</span>).cuda()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.01</span>, weight_decay=<span class="number">0.00001</span>)</span><br><span class="line"></span><br><span class="line">train_losses = []</span><br><span class="line">valid_losses = []</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    model.train()</span><br><span class="line">    t = <span class="number">0</span></span><br><span class="line">    n1 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> id, (heatmaps, coords) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        heatmaps, coords = heatmaps.cuda(), coords.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        out = model(heatmaps)</span><br><span class="line">        </span><br><span class="line">        loss = criterion(out, coords)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        t +=loss.item()</span><br><span class="line">        n1 +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> id%<span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[&#123;&#125;/&#123;&#125;]:train loss:&#123;:.3f&#125;"</span>.format(e,id,loss.item()))</span><br><span class="line">            </span><br><span class="line">    train_losses.append(t/n1)</span><br><span class="line">    v = <span class="number">0</span></span><br><span class="line">    n2 = <span class="number">0</span></span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="keyword">for</span> id, (heatmaps, coords) <span class="keyword">in</span> enumerate(valid_loader):</span><br><span class="line">        heatmaps, coords = heatmaps.cuda(), coords.cuda()</span><br><span class="line">        out = model(heatmaps)</span><br><span class="line">        </span><br><span class="line">        loss = criterion(out, coords)</span><br><span class="line">        v +=loss.item()</span><br><span class="line">        n2 +=<span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> id%<span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"[&#123;&#125;/&#123;&#125;]:valid loss:&#123;:.3f&#125;"</span>.format(e,id,loss.item()))</span><br><span class="line">    </span><br><span class="line">    valid_losses.append(v/n2)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>/<span class="number">0</span>]:train loss:<span class="number">1027.723</span></span><br><span class="line">[<span class="number">0</span>/<span class="number">0</span>]:valid loss:<span class="number">658.191</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">0</span>]:train loss:<span class="number">340.205</span></span><br><span class="line">[<span class="number">1</span>/<span class="number">0</span>]:valid loss:<span class="number">882.184</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">0</span>]:train loss:<span class="number">382.191</span></span><br><span class="line">[<span class="number">2</span>/<span class="number">0</span>]:valid loss:<span class="number">364.457</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">0</span>]:train loss:<span class="number">344.636</span></span><br><span class="line">[<span class="number">3</span>/<span class="number">0</span>]:valid loss:<span class="number">629.423</span></span><br><span class="line">[<span class="number">4</span>/<span class="number">0</span>]:train loss:<span class="number">343.474</span></span><br><span class="line">[<span class="number">4</span>/<span class="number">0</span>]:valid loss:<span class="number">511.996</span></span><br><span class="line">[<span class="number">5</span>/<span class="number">0</span>]:train loss:<span class="number">310.839</span></span><br><span class="line">[<span class="number">5</span>/<span class="number">0</span>]:valid loss:<span class="number">521.019</span></span><br><span class="line">[<span class="number">6</span>/<span class="number">0</span>]:train loss:<span class="number">330.839</span></span><br><span class="line">[<span class="number">6</span>/<span class="number">0</span>]:valid loss:<span class="number">530.305</span></span><br><span class="line">[<span class="number">7</span>/<span class="number">0</span>]:train loss:<span class="number">310.050</span></span><br><span class="line">[<span class="number">7</span>/<span class="number">0</span>]:valid loss:<span class="number">500.017</span></span><br><span class="line">[<span class="number">8</span>/<span class="number">0</span>]:train loss:<span class="number">313.915</span></span><br><span class="line">[<span class="number">8</span>/<span class="number">0</span>]:valid loss:<span class="number">526.495</span></span><br><span class="line">[<span class="number">9</span>/<span class="number">0</span>]:train loss:<span class="number">335.083</span></span><br><span class="line">[<span class="number">9</span>/<span class="number">0</span>]:valid loss:<span class="number">578.623</span></span><br><span class="line">[<span class="number">10</span>/<span class="number">0</span>]:train loss:<span class="number">321.808</span></span><br><span class="line">[<span class="number">10</span>/<span class="number">0</span>]:valid loss:<span class="number">590.830</span></span><br><span class="line">[<span class="number">11</span>/<span class="number">0</span>]:train loss:<span class="number">332.714</span></span><br><span class="line">[<span class="number">11</span>/<span class="number">0</span>]:valid loss:<span class="number">520.583</span></span><br><span class="line">[<span class="number">12</span>/<span class="number">0</span>]:train loss:<span class="number">315.320</span></span><br><span class="line">[<span class="number">12</span>/<span class="number">0</span>]:valid loss:<span class="number">506.796</span></span><br><span class="line">[<span class="number">13</span>/<span class="number">0</span>]:train loss:<span class="number">329.973</span></span><br><span class="line">[<span class="number">13</span>/<span class="number">0</span>]:valid loss:<span class="number">516.331</span></span><br><span class="line">[<span class="number">14</span>/<span class="number">0</span>]:train loss:<span class="number">296.927</span></span><br><span class="line">[<span class="number">14</span>/<span class="number">0</span>]:valid loss:<span class="number">440.843</span></span><br><span class="line">[<span class="number">15</span>/<span class="number">0</span>]:train loss:<span class="number">319.363</span></span><br><span class="line">[<span class="number">15</span>/<span class="number">0</span>]:valid loss:<span class="number">565.522</span></span><br><span class="line">[<span class="number">16</span>/<span class="number">0</span>]:train loss:<span class="number">339.193</span></span><br><span class="line">[<span class="number">16</span>/<span class="number">0</span>]:valid loss:<span class="number">630.012</span></span><br><span class="line">[<span class="number">17</span>/<span class="number">0</span>]:train loss:<span class="number">319.562</span></span><br><span class="line">[<span class="number">17</span>/<span class="number">0</span>]:valid loss:<span class="number">588.987</span></span><br><span class="line">[<span class="number">18</span>/<span class="number">0</span>]:train loss:<span class="number">325.077</span></span><br><span class="line">[<span class="number">18</span>/<span class="number">0</span>]:valid loss:<span class="number">555.196</span></span><br><span class="line">[<span class="number">19</span>/<span class="number">0</span>]:train loss:<span class="number">324.888</span></span><br><span class="line">[<span class="number">19</span>/<span class="number">0</span>]:valid loss:<span class="number">504.099</span></span><br><span class="line">[<span class="number">20</span>/<span class="number">0</span>]:train loss:<span class="number">328.839</span></span><br><span class="line">[<span class="number">20</span>/<span class="number">0</span>]:valid loss:<span class="number">501.208</span></span><br><span class="line">[<span class="number">21</span>/<span class="number">0</span>]:train loss:<span class="number">322.016</span></span><br></pre></td></tr></table></figure>
<p>​<br>
​ ......</p>
<p>​<br>
​ ......</p>
<p>​<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">489</span>/<span class="number">0</span>]:train loss:<span class="number">313.746</span></span><br><span class="line">[<span class="number">489</span>/<span class="number">0</span>]:valid loss:<span class="number">498.646</span></span><br><span class="line">[<span class="number">490</span>/<span class="number">0</span>]:train loss:<span class="number">331.695</span></span><br><span class="line">[<span class="number">490</span>/<span class="number">0</span>]:valid loss:<span class="number">570.283</span></span><br><span class="line">[<span class="number">491</span>/<span class="number">0</span>]:train loss:<span class="number">308.808</span></span><br><span class="line">[<span class="number">491</span>/<span class="number">0</span>]:valid loss:<span class="number">543.668</span></span><br><span class="line">[<span class="number">492</span>/<span class="number">0</span>]:train loss:<span class="number">331.526</span></span><br><span class="line">[<span class="number">492</span>/<span class="number">0</span>]:valid loss:<span class="number">609.543</span></span><br><span class="line">[<span class="number">493</span>/<span class="number">0</span>]:train loss:<span class="number">314.055</span></span><br><span class="line">[<span class="number">493</span>/<span class="number">0</span>]:valid loss:<span class="number">530.251</span></span><br><span class="line">[<span class="number">494</span>/<span class="number">0</span>]:train loss:<span class="number">303.886</span></span><br><span class="line">[<span class="number">494</span>/<span class="number">0</span>]:valid loss:<span class="number">557.143</span></span><br><span class="line">[<span class="number">495</span>/<span class="number">0</span>]:train loss:<span class="number">321.458</span></span><br><span class="line">[<span class="number">495</span>/<span class="number">0</span>]:valid loss:<span class="number">543.295</span></span><br><span class="line">[<span class="number">496</span>/<span class="number">0</span>]:train loss:<span class="number">311.247</span></span><br><span class="line">[<span class="number">496</span>/<span class="number">0</span>]:valid loss:<span class="number">497.568</span></span><br><span class="line">[<span class="number">497</span>/<span class="number">0</span>]:train loss:<span class="number">326.582</span></span><br><span class="line">[<span class="number">497</span>/<span class="number">0</span>]:valid loss:<span class="number">515.231</span></span><br><span class="line">[<span class="number">498</span>/<span class="number">0</span>]:train loss:<span class="number">333.465</span></span><br><span class="line">[<span class="number">498</span>/<span class="number">0</span>]:valid loss:<span class="number">553.942</span></span><br><span class="line">[<span class="number">499</span>/<span class="number">0</span>]:train loss:<span class="number">308.450</span></span><br><span class="line">[<span class="number">499</span>/<span class="number">0</span>]:valid loss:<span class="number">573.775</span></span><br><span class="line">[<span class="number">500</span>/<span class="number">0</span>]:train loss:<span class="number">304.610</span></span><br><span class="line">[<span class="number">500</span>/<span class="number">0</span>]:valid loss:<span class="number">585.026</span></span><br><span class="line">[<span class="number">501</span>/<span class="number">0</span>]:train loss:<span class="number">325.851</span></span><br><span class="line">[<span class="number">501</span>/<span class="number">0</span>]:valid loss:<span class="number">577.704</span></span><br><span class="line">[<span class="number">502</span>/<span class="number">0</span>]:train loss:<span class="number">313.319</span></span><br><span class="line">[<span class="number">502</span>/<span class="number">0</span>]:valid loss:<span class="number">510.165</span></span><br><span class="line">[<span class="number">503</span>/<span class="number">0</span>]:train loss:<span class="number">301.331</span></span><br><span class="line">[<span class="number">503</span>/<span class="number">0</span>]:valid loss:<span class="number">563.254</span></span><br><span class="line">[<span class="number">504</span>/<span class="number">0</span>]:train loss:<span class="number">294.513</span></span><br><span class="line">[<span class="number">504</span>/<span class="number">0</span>]:valid loss:<span class="number">550.867</span></span><br><span class="line">[<span class="number">505</span>/<span class="number">0</span>]:train loss:<span class="number">337.322</span></span><br><span class="line">[<span class="number">505</span>/<span class="number">0</span>]:valid loss:<span class="number">405.499</span></span><br><span class="line">[<span class="number">506</span>/<span class="number">0</span>]:train loss:<span class="number">210.640</span></span><br><span class="line">[<span class="number">506</span>/<span class="number">0</span>]:valid loss:<span class="number">440.354</span></span><br><span class="line">[<span class="number">507</span>/<span class="number">0</span>]:train loss:<span class="number">177.821</span></span><br><span class="line">[<span class="number">507</span>/<span class="number">0</span>]:valid loss:<span class="number">372.500</span></span><br><span class="line">[<span class="number">508</span>/<span class="number">0</span>]:train loss:<span class="number">152.111</span></span><br><span class="line">[<span class="number">508</span>/<span class="number">0</span>]:valid loss:<span class="number">314.090</span></span><br><span class="line">[<span class="number">509</span>/<span class="number">0</span>]:train loss:<span class="number">150.206</span></span><br><span class="line">[<span class="number">509</span>/<span class="number">0</span>]:valid loss:<span class="number">531.095</span></span><br><span class="line">[<span class="number">510</span>/<span class="number">0</span>]:train loss:<span class="number">131.546</span></span><br><span class="line">[<span class="number">510</span>/<span class="number">0</span>]:valid loss:<span class="number">320.094</span></span><br><span class="line">[<span class="number">511</span>/<span class="number">0</span>]:train loss:<span class="number">124.478</span></span><br><span class="line">[<span class="number">511</span>/<span class="number">0</span>]:valid loss:<span class="number">348.056</span></span><br><span class="line">[<span class="number">512</span>/<span class="number">0</span>]:train loss:<span class="number">82.704</span></span><br><span class="line">[<span class="number">512</span>/<span class="number">0</span>]:valid loss:<span class="number">138.187</span></span><br><span class="line">[<span class="number">513</span>/<span class="number">0</span>]:train loss:<span class="number">93.763</span></span><br><span class="line">[<span class="number">513</span>/<span class="number">0</span>]:valid loss:<span class="number">59.943</span></span><br><span class="line">[<span class="number">514</span>/<span class="number">0</span>]:train loss:<span class="number">28.917</span></span><br><span class="line">[<span class="number">514</span>/<span class="number">0</span>]:valid loss:<span class="number">83.261</span></span><br><span class="line">[<span class="number">515</span>/<span class="number">0</span>]:train loss:<span class="number">26.591</span></span><br><span class="line">[<span class="number">515</span>/<span class="number">0</span>]:valid loss:<span class="number">103.014</span></span><br><span class="line">[<span class="number">516</span>/<span class="number">0</span>]:train loss:<span class="number">20.655</span></span><br><span class="line">[<span class="number">516</span>/<span class="number">0</span>]:valid loss:<span class="number">90.283</span></span><br><span class="line">[<span class="number">517</span>/<span class="number">0</span>]:train loss:<span class="number">14.670</span></span><br><span class="line">[<span class="number">517</span>/<span class="number">0</span>]:valid loss:<span class="number">86.509</span></span><br><span class="line">[<span class="number">518</span>/<span class="number">0</span>]:train loss:<span class="number">7.979</span></span><br><span class="line">[<span class="number">518</span>/<span class="number">0</span>]:valid loss:<span class="number">81.485</span></span><br><span class="line">[<span class="number">519</span>/<span class="number">0</span>]:train loss:<span class="number">5.293</span></span><br><span class="line">[<span class="number">519</span>/<span class="number">0</span>]:valid loss:<span class="number">82.389</span></span><br><span class="line">[<span class="number">520</span>/<span class="number">0</span>]:train loss:<span class="number">6.404</span></span><br><span class="line">[<span class="number">520</span>/<span class="number">0</span>]:valid loss:<span class="number">79.925</span></span><br><span class="line">[<span class="number">521</span>/<span class="number">0</span>]:train loss:<span class="number">4.992</span></span><br><span class="line">[<span class="number">521</span>/<span class="number">0</span>]:valid loss:<span class="number">73.615</span></span><br><span class="line">[<span class="number">522</span>/<span class="number">0</span>]:train loss:<span class="number">2.514</span></span><br><span class="line">[<span class="number">522</span>/<span class="number">0</span>]:valid loss:<span class="number">68.852</span></span><br><span class="line">[<span class="number">523</span>/<span class="number">0</span>]:train loss:<span class="number">3.168</span></span><br><span class="line">[<span class="number">523</span>/<span class="number">0</span>]:valid loss:<span class="number">61.463</span></span><br><span class="line">[<span class="number">524</span>/<span class="number">0</span>]:train loss:<span class="number">2.194</span></span><br><span class="line">[<span class="number">524</span>/<span class="number">0</span>]:valid loss:<span class="number">58.418</span></span><br><span class="line">[<span class="number">525</span>/<span class="number">0</span>]:train loss:<span class="number">3.485</span></span><br><span class="line">[<span class="number">525</span>/<span class="number">0</span>]:valid loss:<span class="number">55.320</span></span><br><span class="line">[<span class="number">526</span>/<span class="number">0</span>]:train loss:<span class="number">2.697</span></span><br><span class="line">[<span class="number">526</span>/<span class="number">0</span>]:valid loss:<span class="number">46.612</span></span><br><span class="line">[<span class="number">527</span>/<span class="number">0</span>]:train loss:<span class="number">4.031</span></span><br><span class="line">[<span class="number">527</span>/<span class="number">0</span>]:valid loss:<span class="number">42.675</span></span><br><span class="line">[<span class="number">528</span>/<span class="number">0</span>]:train loss:<span class="number">3.537</span></span><br><span class="line">[<span class="number">528</span>/<span class="number">0</span>]:valid loss:<span class="number">35.026</span></span><br><span class="line">[<span class="number">529</span>/<span class="number">0</span>]:train loss:<span class="number">2.433</span></span><br><span class="line">[<span class="number">529</span>/<span class="number">0</span>]:valid loss:<span class="number">21.490</span></span><br><span class="line">[<span class="number">530</span>/<span class="number">0</span>]:train loss:<span class="number">1.950</span></span><br><span class="line">[<span class="number">530</span>/<span class="number">0</span>]:valid loss:<span class="number">6.599</span></span><br><span class="line">[<span class="number">531</span>/<span class="number">0</span>]:train loss:<span class="number">1.498</span></span><br><span class="line">[<span class="number">531</span>/<span class="number">0</span>]:valid loss:<span class="number">0.874</span></span><br><span class="line">[<span class="number">532</span>/<span class="number">0</span>]:train loss:<span class="number">0.641</span></span><br><span class="line">[<span class="number">532</span>/<span class="number">0</span>]:valid loss:<span class="number">0.786</span></span><br><span class="line">[<span class="number">533</span>/<span class="number">0</span>]:train loss:<span class="number">1.632</span></span><br><span class="line">[<span class="number">533</span>/<span class="number">0</span>]:valid loss:<span class="number">0.256</span></span><br><span class="line">[<span class="number">534</span>/<span class="number">0</span>]:train loss:<span class="number">0.318</span></span><br><span class="line">[<span class="number">534</span>/<span class="number">0</span>]:valid loss:<span class="number">1.699</span></span><br><span class="line">[<span class="number">535</span>/<span class="number">0</span>]:train loss:<span class="number">3.042</span></span><br><span class="line">[<span class="number">535</span>/<span class="number">0</span>]:valid loss:<span class="number">1.706</span></span><br><span class="line">[<span class="number">536</span>/<span class="number">0</span>]:train loss:<span class="number">1.189</span></span><br><span class="line">[<span class="number">536</span>/<span class="number">0</span>]:valid loss:<span class="number">1.651</span></span><br><span class="line">[<span class="number">537</span>/<span class="number">0</span>]:train loss:<span class="number">4.311</span></span><br><span class="line">[<span class="number">537</span>/<span class="number">0</span>]:valid loss:<span class="number">1.211</span></span><br><span class="line">[<span class="number">538</span>/<span class="number">0</span>]:train loss:<span class="number">2.011</span></span><br><span class="line">[<span class="number">538</span>/<span class="number">0</span>]:valid loss:<span class="number">4.156</span></span><br><span class="line">[<span class="number">539</span>/<span class="number">0</span>]:train loss:<span class="number">2.527</span></span><br><span class="line">[<span class="number">539</span>/<span class="number">0</span>]:valid loss:<span class="number">1.380</span></span><br><span class="line">[<span class="number">540</span>/<span class="number">0</span>]:train loss:<span class="number">1.754</span></span><br><span class="line">[<span class="number">540</span>/<span class="number">0</span>]:valid loss:<span class="number">7.980</span></span><br><span class="line">[<span class="number">541</span>/<span class="number">0</span>]:train loss:<span class="number">4.717</span></span><br><span class="line">[<span class="number">541</span>/<span class="number">0</span>]:valid loss:<span class="number">7.452</span></span><br><span class="line">[<span class="number">542</span>/<span class="number">0</span>]:train loss:<span class="number">2.004</span></span><br><span class="line">[<span class="number">542</span>/<span class="number">0</span>]:valid loss:<span class="number">0.953</span></span><br><span class="line">[<span class="number">543</span>/<span class="number">0</span>]:train loss:<span class="number">1.676</span></span><br><span class="line">[<span class="number">543</span>/<span class="number">0</span>]:valid loss:<span class="number">0.460</span></span><br><span class="line">[<span class="number">544</span>/<span class="number">0</span>]:train loss:<span class="number">1.610</span></span><br><span class="line">[<span class="number">544</span>/<span class="number">0</span>]:valid loss:<span class="number">0.386</span></span><br><span class="line">[<span class="number">545</span>/<span class="number">0</span>]:train loss:<span class="number">0.336</span></span><br><span class="line">[<span class="number">545</span>/<span class="number">0</span>]:valid loss:<span class="number">0.584</span></span><br></pre></td></tr></table></figure></p>
<p>​<br>
​ ...... ​<br>
​ ......</p>
<p>​<br>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">992</span>/<span class="number">0</span>]:train loss:<span class="number">0.056</span></span><br><span class="line">[<span class="number">992</span>/<span class="number">0</span>]:valid loss:<span class="number">0.034</span></span><br><span class="line">[<span class="number">993</span>/<span class="number">0</span>]:train loss:<span class="number">0.034</span></span><br><span class="line">[<span class="number">993</span>/<span class="number">0</span>]:valid loss:<span class="number">0.043</span></span><br><span class="line">[<span class="number">994</span>/<span class="number">0</span>]:train loss:<span class="number">0.051</span></span><br><span class="line">[<span class="number">994</span>/<span class="number">0</span>]:valid loss:<span class="number">0.050</span></span><br><span class="line">[<span class="number">995</span>/<span class="number">0</span>]:train loss:<span class="number">0.041</span></span><br><span class="line">[<span class="number">995</span>/<span class="number">0</span>]:valid loss:<span class="number">0.061</span></span><br><span class="line">[<span class="number">996</span>/<span class="number">0</span>]:train loss:<span class="number">0.108</span></span><br><span class="line">[<span class="number">996</span>/<span class="number">0</span>]:valid loss:<span class="number">0.389</span></span><br><span class="line">[<span class="number">997</span>/<span class="number">0</span>]:train loss:<span class="number">0.539</span></span><br><span class="line">[<span class="number">997</span>/<span class="number">0</span>]:valid loss:<span class="number">0.133</span></span><br><span class="line">[<span class="number">998</span>/<span class="number">0</span>]:train loss:<span class="number">0.250</span></span><br><span class="line">[<span class="number">998</span>/<span class="number">0</span>]:valid loss:<span class="number">0.107</span></span><br><span class="line">[<span class="number">999</span>/<span class="number">0</span>]:train loss:<span class="number">0.247</span></span><br><span class="line">[<span class="number">999</span>/<span class="number">0</span>]:valid loss:<span class="number">1.734</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">mpl.style.use(<span class="string">'seaborn-bright'</span>)</span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">epochnum = list(range(<span class="number">0</span>,len(train_losses)))</span><br><span class="line"></span><br><span class="line">plt.plot(epochnum, train_losses, color=<span class="string">'black'</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.plot(epochnum, valid_losses, color=<span class="string">'red'</span>,linewidth=<span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>, fontdict=&#123;<span class="string">'family'</span>:<span class="string">'Arial'</span>&#125;)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>,fontdict=&#123;<span class="string">'family'</span>:<span class="string">'Arial'</span>&#125;)</span><br><span class="line">plt.xlim(<span class="number">0</span>, len(train_losses))</span><br><span class="line"></span><br><span class="line">plt.legend((<span class="string">'Train'</span>,</span><br><span class="line">            <span class="string">'Valid'</span>), loc=<span class="string">'best'</span>,fontsize=<span class="number">16</span>)</span><br><span class="line">plt.title(<span class="string">"generalization error with coordadd by CoordConv"</span>)</span><br><span class="line"></span><br><span class="line">plt.grid(linestyle=<span class="string">':'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2020/09/22/coordconv/image-20200922211755053.png" alt="image-20200922211755053"><figcaption>image-20200922211755053</figcaption>
</figure>
<h3 id="真的是太神奇了为什么在低500个周期开始急速收敛">真的是太神奇了，为什么在低500个周期开始急速收敛？？</h3>
<p>训练loss和验证的loss，开始极速收敛！</p>
<p>我怀疑这个代价函数的优化曲面有一个非常难以跳出的局部最优解，因为我的训练集和验证集的数据分布之间有一个非常明显的GAP！</p>
<p>如果能有人看到这个，和我探讨一下这个问题就好了！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">9</span>, <span class="number">4.5</span>), tight_layout=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> heatmap, pos <span class="keyword">in</span> train_set:</span><br><span class="line">    x = pos[<span class="number">0</span>]</span><br><span class="line">    y = pos[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">0</span>].scatter(x, y, c=<span class="string">'red'</span>, s=<span class="number">3</span>)</span><br><span class="line">    out = model(heatmap.unsqueeze(<span class="number">0</span>).cuda()).squeeze().detach().cpu().numpy()</span><br><span class="line">    x = out[<span class="number">0</span>]</span><br><span class="line">    y = out[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">1</span>].scatter(x, y, c=<span class="string">'red'</span>, s=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> heatmap, pos <span class="keyword">in</span> valid_set:</span><br><span class="line">    x = pos[<span class="number">0</span>]</span><br><span class="line">    y = pos[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">0</span>].scatter(x, y, c=<span class="string">'blue'</span>, s=<span class="number">3</span>)</span><br><span class="line">    out = model(heatmap.unsqueeze(<span class="number">0</span>).cuda()).squeeze().detach().cpu().numpy()</span><br><span class="line">    x = out[<span class="number">0</span>]</span><br><span class="line">    y = out[<span class="number">1</span>]</span><br><span class="line">    ax[<span class="number">1</span>].scatter(x, y, c=<span class="string">'blue'</span>, s=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.xlim(<span class="number">0</span>, w)</span><br><span class="line">plt.ylim(<span class="number">0</span>, h)</span><br><span class="line">plt.title(<span class="string">"Unable to predict coords with coordadd by CoordMLP"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/2020/09/22/coordconv/image-20200922211812693.png" alt="image-20200922211812693"><figcaption>image-20200922211812693</figcaption>
</figure>
<h4 id="很明显这个coordconv的网络具备了非常神奇的预测位置的能力">很明显，这个CoordConv的网络具备了非常神奇的预测位置的能力。</h4>
<h4 id="并且获取这个坐标回归能力是突然在某个周期获得的">并且获取这个坐标回归能力是突然在某个周期获得的！！！</h4>
<h4 id="后面还会继续思考这个问题">后面还会继续思考这个问题～</h4>
<blockquote>
<p>In this work, we expose and analyze a generic inability of CNNs to transform spatial representations between two different types: from a dense Cartesian representation to a sparse, pixel-based represen- tation or in the opposite direction. Though such transformations would seem simple for networks to learn, it turns out to be more difficult than expected, at least when models are comprised of the commonly used stacks of convolutional layers. While straightforward stacks of convolutional layers excel at tasks like image classification, they are not quite the right model for coordinate transform.</p>
</blockquote>
<blockquote>
<p>Throughout the rest of the paper, we examine the coordinate transform problem starting with the simplest scenario and ending with the most complex. Although results on toy problems should generally be taken with a degree of skepticism, starting small allows us to pinpoint the issue, exploring and understanding it in detail. Later sections then show that the phenomenon observed in the toy domain indeed appears in more real-world settings.</p>
<p>We begin by showing that coordinate transforms are surprisingly difficult even when the problem is <em>small and supervised</em>. In the <em>Supervised Coordinate Classification</em> task, given a pixel’s (x, y) coordinates as input, we train a CNN to highlight it as output. The <em>Supervised Coordinate Regression</em> task entails the inverse: given an input image containing a single white pixel, output its coordinates. We show that both problems are harder than expected using convolutional layers but become trivial by using a CoordConv layer (Section 4).</p>
</blockquote>
<h2 id="调参">调参：</h2>
<ul>
<li>增加靠近输出的CoordConv层</li>
<li>坐标归一化</li>
<li>数值尺度控制</li>
</ul>
<p>CoordConv在相同优化条件下，只用了100个周期内就很快收敛，并且获得了很强的泛化能力。</p>
<p>我进行了</p>
<ul>
<li>pooling前 map的可视化</li>
<li>CoordConv在不同大小的one-hot heatmap的数据集的泛化能力测试</li>
</ul>
<figure>
<img src="/2020/09/22/coordconv/output.gif" alt="output"><figcaption>output</figcaption>
</figure>
<figure>
<img src="/2020/09/22/coordconv/image-20200924145925184.png" alt="image-20200924145925184"><figcaption>image-20200924145925184</figcaption>
</figure>

      
    </div>
    
    
    

    

    

    
      <div>
        
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Author：</strong>
    yangsenius
  </li>
  <li class="post-copyright-link">
    <strong>Link：</strong>
    <a href="http://senyang-ml.github.io/2020/09/22/coordconv/" title="CoordConv - My Surprising Finding.">http://senyang-ml.github.io/2020/09/22/coordconv/</a>
  </li>
  <li class="post-copyright-license">
    <strong>License： </strong>
    Unless otherwise stated,  all blogs use the <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> protocol, please indicate the source
  </li>
</ul>


      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/Reproduce/" rel="tag"># Reproduce</a>
          
            <a href="/tags/Neural-Network/" rel="tag"># Neural Network</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        
          <div class="wp_rating">
            <div id="wpac-rating"></div>
          </div>
        

        

        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/06/04/detr/" rel="next" title="Detr">
                <i class="fa fa-chevron-left"></i> Detr
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Toc
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">杨森 & yangsenius</p>
              <p class="site-description motion-element" itemprop="description">Talk is not cheap</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:yangsenius@seu.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#coordconv-的研究与分析"><span class="nav-number">1.</span> <span class="nav-text">CoordConv 的研究与分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#可视化mlp的权重参数"><span class="nav-number">1.1.</span> <span class="nav-text">可视化MLP的权重参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#coordmlp不具备预测坐标的泛化性能"><span class="nav-number">1.2.</span> <span class="nav-text">CoordMLP不具备预测坐标的泛化性能</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#coordconv-怎么样呢"><span class="nav-number">2.</span> <span class="nav-text">CoordConv 怎么样呢？</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#真的是太神奇了为什么在低500个周期开始急速收敛"><span class="nav-number">2.0.1.</span> <span class="nav-text">真的是太神奇了，为什么在低500个周期开始急速收敛？？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#很明显这个coordconv的网络具备了非常神奇的预测位置的能力"><span class="nav-number">2.0.1.1.</span> <span class="nav-text">很明显，这个CoordConv的网络具备了非常神奇的预测位置的能力。</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#并且获取这个坐标回归能力是突然在某个周期获得的"><span class="nav-number">2.0.1.2.</span> <span class="nav-text">并且获取这个坐标回归能力是突然在某个周期获得的！！！</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#后面还会继续思考这个问题"><span class="nav-number">2.0.1.3.</span> <span class="nav-text">后面还会继续思考这个问题～</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#调参"><span class="nav-number">2.1.</span> <span class="nav-text">调参：</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">杨森 & yangsenius</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  









  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three-waves.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  











<!-- LOCAL: You can save these files to your site and update links -->
  
<!-- END LOCAL -->


    
      <script src="https://utteranc.es/client.js"
        repo="senyang-ml/Comments"
        issue-term="title"
        label="utt-comment"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>

      
    






  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  <script type="text/javascript">
  wpac_init = window.wpac_init || [];
  wpac_init.push({widget: 'Rating', id: ,
    el: 'wpac-rating',
    color: 'fc6423'
  });
  (function() {
    if ('WIDGETPACK_LOADED' in window) return;
    WIDGETPACK_LOADED = true;
    var mc = document.createElement('script');
    mc.type = 'text/javascript';
    mc.async = true;
    mc.src = '//embed.widgetpack.com/widget.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
  })();
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


      
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  

</body>
</html>
