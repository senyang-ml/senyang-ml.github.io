<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning,Capsule Network,Unsupervised Learning,PPT," />




  


  <link rel="alternate" href="/atom.xml" title="Sen Yang" type="application/atom+xml" />






<meta name="description" content="1. 引言 《stacked capsule autoencoders》使用无监督的方式达到了98.5%的MNIST分类准确率。 Stacked Capsule Autoencoders 发表在 NeurIPS-2019，作者团队阵容豪华。可以说是官方capsule的第3个版本。前两个版本的是：  Dynamic Routing Between Capsules Matrix capsule wi">
<meta property="og:type" content="article">
<meta property="og:title" content="Stacked Capsule Autoencoders-堆叠的胶囊自编码器">
<meta property="og:url" content="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/index.html">
<meta property="og:site_name" content="Sen Yang">
<meta property="og:description" content="1. 引言 《stacked capsule autoencoders》使用无监督的方式达到了98.5%的MNIST分类准确率。 Stacked Capsule Autoencoders 发表在 NeurIPS-2019，作者团队阵容豪华。可以说是官方capsule的第3个版本。前两个版本的是：  Dynamic Routing Between Capsules Matrix capsule wi">
<meta property="og:image" content="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/scae.jpg">
<meta property="og:image" content="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/coincidence-filtering.jpg">
<meta property="article:published_time" content="2020-02-11T11:18:17.000Z">
<meta property="article:modified_time" content="2020-05-24T06:13:18.928Z">
<meta property="article:author" content="yangsenius">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Capsule Network">
<meta property="article:tag" content="Unsupervised Learning">
<meta property="article:tag" content="PPT">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/scae.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/"/>





  <title>Stacked Capsule Autoencoders-堆叠的胶囊自编码器 | Sen Yang</title>
  








<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Sen Yang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-blogs">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Blogs
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/Archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/research/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="yangsenius">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sen Yang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Stacked Capsule Autoencoders-堆叠的胶囊自编码器</h1>
        

        <div class="post-meta">
                  

          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-11T19:18:17+08:00">
                2020-02-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="引言">1. 引言</h2>
<p>《stacked capsule autoencoders》使用无监督的方式达到了98.5%的MNIST分类准确率。 <a href="https://arxiv.org/abs/1906.06818" target="_blank" rel="noopener">Stacked Capsule Autoencoders</a> 发表在 NeurIPS-2019，作者团队阵容豪华。可以说是官方capsule的第3个版本。前两个版本的是：</p>
<ul>
<li><a href="https://arxiv.org/abs/1710.09829" target="_blank" rel="noopener">Dynamic Routing Between Capsules</a></li>
<li><a href="https://openreview.net/pdf?id=HJWLfGWRb" target="_blank" rel="noopener">Matrix capsule with EM routing</a></li>
</ul>
<a id="more"></a>
<p>当然还有最早的<a href="http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf" target="_blank" rel="noopener">Transforming Auto-encoders</a>，发表在2011年ICANN，论文第一次引入“capsule”的概念。值得一提的是，这篇论文的作者是Hinton、Alex Krizhevsky等人，对，是AlexNet的Alex。原来Alex本人在2012年发表AlexNet之前在研究这种“奇怪”的东西。2011年的他可能没想到，第二年的他们，为了参与ImageNet大规模数据集图像识别挑战赛而设计的一款基于的传统CNN的AlexNet，引爆了接下来已经持续7年之久的“Deep Learning”潮流，现如今CVPR 2020投稿量都过10000了，是谁惹得“祸“的还不清楚吗？</p>
<h2 id="概念">2. 概念</h2>
<p>从2017年开始， Hinton等人研究的Capsule Network得到了深度学习社区的大量关注。可以说Capsule Network在反思CNN的一些固有偏见，比如CNN的学习过分强调不变性（invariant ）特征的学习，数据增强也服务于这一目的。而这样做，实际上，忽略了一个真实世界中的事实：</p>
<p>1）<strong>物体-部件 关系（Object-Part-relationship）是视角不变的（viewpoint invariant）</strong>， 2）<strong>物体-观察者（Object-Viewer-relationship） 是视角同变性（viewpoint equivariant）的</strong>。</p>
<p>equivariant：<span class="math inline">\(\forall_{T \in \mathcal{T}} Tf(\mathbf{x}) = f(T\mathbf{x})\)</span> invariant： <span class="math inline">\(\forall_{T \in \mathcal{T}} Tf(\mathbf{x}) = f(T\mathbf{x})\)</span></p>
<p>并且Capsule强调物体的存在是因为当部件以合理的关系组合才得以存在，所以进一步引出了routing的机制，来发掘part-whole关系。</p>
<p>Matrix Capsule的那篇论文中提出，用混合高斯模型来学习这些关系，并提出了EM routing的算法，它从GMM和EM的角度，解释为更低层capsule与更高层capsule之间的自聚类算法。然而这种计算一旦放在前向传播会大大增加计算量，这也是其模型理论受限的部分， 所以其实验数据集主打还是MNIST, SmallNorb，如果换做更大一点的ImageNet, COCO，不知道Capsule的精深理念能不能发扬光大。可能Hinton深知自己的先驱身份所以他应该相信后面会有人帮他填满这些实验？</p>
<p>不过这种Gaussian Mixture的建模方式是非常合理的，一是GMM作为生成模型，自身就具备很强的解释性，二是这种参数学习以极大似然估计的方式，不再过分依赖梯度回传的更新机制，所以GMM的思想继续用在了Stacked Capsule Autoencoder里面。</p>
<blockquote>
<p>这里想说的是: 如果有人问，当前深度学习的核心理念是什么，我个人觉得，一个比较好的回答就是，学习目标形式化进而转换为参数的梯度学习。然而这样的同质研究越来越多，又越来越难以深入其内部，DL社区就开始自我反思。而Capsule的理念里面，就尝试去摆脱D中L对梯度回传的过分依赖，对卷积结构的过分依赖，所以Capsule Network本身将一些自编码器、重构、混合高斯、注意力等机制引入其中。</p>
</blockquote>
<p>其实读这篇论文会感觉作者用到的技术太多了，很容易忽略它背后的动机。我个人对它背后动机的理解为: 将图像中的实例的部件及属性从像素二维空间中以像素重建的方式抽取出出来；再用重构的方式解释部件与整体的关系。这也是SACE的两个主要构成环节。</p>
<p>接下来，本文希望通过简洁的语言来描述该论文的主要思路，所以跳过了论文对Toy Setup的描述，直接总结了SCAE的两个主要模块。</p>
<h2 id="stacked-capsule-autoencoders-scae">3. Stacked Capsule Autoencoders (SCAE)</h2>
<h3 id="scae-pcae-ocae">SCAE = PCAE +OCAE</h3>
<p>(Part Capsule Autoencoder + Object Capsule Autoencoder)</p>
<p>以这幅官方给出的这幅示意图为例</p>
<figure>
<img src="/2020/02/11/stacked-capsule-autoencoders/scae.jpg" alt="SCAE"><figcaption>SCAE</figcaption>
</figure>
<h4 id="pace">PACE</h4>
<p><strong>目标</strong>：将 <span class="math inline">\(h\times w \times c\)</span> 的图像，编码成 <span class="math inline">\(M\)</span> 个part capsules，每个part capsule能够对应图像中的一种部件part的所有属性，用多个属性构成的一个向量 <span class="math inline">\(X \in R^{6+1+z_m}\)</span> 来表示一个part实例，这个实例属性中包括6维的姿态，1维的存在概率和 <span class="math inline">\(z_m\)</span> 维的自身独特性特征。</p>
<p><strong>编码方法</strong>：采用CNN+Attention Pooling 方式:</p>
<p><span class="math display">\[
h\times w\times c \Rightarrow M \times X 
\]</span></p>
<p><strong>解码方法</strong>：可学习的<span class="math inline">\(M\)</span>个 <span class="math inline">\(11\times 11\)</span>大小的模板+仿射变换（6维姿态导出）</p>
<p><strong>学习训练方法</strong>：用可学习的模板，进行高斯混合来重构原始图像+所有位置上的像素数据的极大似然估计</p>
<h4 id="oace">OACE</h4>
<p><strong>目标</strong>：把 part capsules当成 <span class="math inline">\(M\)</span> 个 <span class="math inline">\(X\)</span> 构成的集合，使用 Set Transformer学习集合中元素与元素之间的成对关系以及高阶的关系，来预测 <span class="math inline">\(K\)</span> 个object capsules，每个object capsule能够对应图像中的一个物体的所有属性，用多个属性构成的一个向量 <span class="math inline">\(Y \in R^{9+1+z_k}\)</span> 来表示一个part实例，这个实例属性中包括9维的object-viewer-matrix，1维的存在概率和 <span class="math inline">\(z_K\)</span> 维的自身独特性特征。然后对每个object capsule 使用MLP解码出，每个object capsule与所有part capsule之间的隶属关系，使用高斯混合模型来建模，即part capsule m的姿态 <span class="math inline">\(x_m\)</span>的可以看成是多个object capsule的贡献的高斯混合, 那么第 <span class="math inline">\(k\)</span> 个object capsule 对第 <span class="math inline">\(m\)</span> 个part capsule的贡献为 <span class="math inline">\(p(x_m|k,m)\)</span></p>
<p><strong>编码方法</strong>：Set Transformer 学习集合中各个元素的pair-wise关系以及高阶的关系，是permutation-invariant的模型。输出 <span class="math inline">\(K\)</span> 个object capsules实例</p>
<p><strong>解码方法</strong>：用 <span class="math inline">\(K\)</span> 个MLP预测高斯混合模型（详见论文中的公式）的候选投票，一个是方差，然后计算出高斯混合模型每个高斯成分的均值和方差，这样就可以计算出 <span class="math inline">\(p(x_m|k,m)\)</span>。</p>
<p><strong>学习训练方法</strong>：部件part-capsule及其属性，被物体object-capsule整体下的高斯混合来进行重构解释的极大似然估计</p>
<h2 id="aaai-2020-hinton发表了关于stacked-capsule-autoencoder的演讲">4. AAAI 2020 Hinton发表了关于Stacked Capsule AutoEncoder的演讲</h2>
<p>演讲地址在：<a href="https://www.bilibili.com/video/av88128940" target="_blank" rel="noopener">Geoffrey Hinton：Stacked Capsule Autoencoders(堆叠胶囊自编码器) (AAAI 2020)_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili</a></p>
<p><strong>矩阵具备很好的同变性（equivariant）的性质，仿射矩阵可以发挥出出奇的作用。</strong></p>
<p>他还提到了一个很有意思的概念：Coincidence Fitering</p>
<p>他指出了现在的CNN的问题 并没有很好的利用--偶然性过滤，但是Transformer的注意力机制中体现出了偶然性过滤</p>
<p>我比较喜欢，这种用恰到好处的语言来描述提炼出一个抽象的解释性名词，既形象生动，又直指核心问题</p>
<h4 id="什么叫偶然性过滤">什么叫偶然性过滤？</h4>
<p>我个人的直觉理解是，CNN主要做的是卷积核的权重与激活值的矩阵乘法（或者说是向量的内积），那么由于输出目标监督是稀疏的（groudtruth往往是稀疏的，无论是分类还是回归，坐标还是热图），就会让中间的激活也倾向于是稀疏的，也就是说，大部分的权重矩阵与激活向量的乘法运算时对应元素的取值倾向，是无关的，或者说他们的对应取值是偶然的，这样的值是不显著的，容易会被不激活，但是问题是，这种稀疏激活模式，并不是发生在两个高维激活向量之间，而是可学习的权重和神经元的激活值之间，而真正的偶然性过滤需要发生在两个高维向量之间的某些对应元素上，比如两个10000维的向量在第2437位上具备相似的取值，而其他元素对应不存在什么关系，这种两个偶然性中出现的一致是不平凡的，那么其他平凡的偶然性就会被过滤掉。Transformer中的注意力机制就是高维向量间的内积，就会形成一种covariance structure，它会过滤掉大部分偶然的输入 (非目标输入)，只有契合该covariance structure的输入才能形成明显的激活！</p>
<p>(上述是我的直觉理解，描述不一定准确, 期待有更多的讨论和解读)</p>
<p><img src="/2020/02/11/stacked-capsule-autoencoders/coincidence-filtering.jpg" alt="SCAE"> &gt; [!NOTE] &gt;（~而且有时候，我们的实验结果和结论都有可能是“偶然的”）</p>
<p>演讲地址在：<a href="https://www.bilibili.com/video/av88128940" target="_blank" rel="noopener">Geoffrey Hinton：Stacked Capsule Autoencoders(堆叠胶囊自编码器) (AAAI 2020)_哔哩哔哩 (゜-゜)つロ 干杯~-bilibili</a> 另外，我也整理出了关于 Dynamic Routing Between Capsules，Matrix capsule with EM routing 和 Stacked Capsule Autoencoders 的PPT。百度云盘地址：https://pan.baidu.com/s/1BCdJiNWGqD-SNao7Lmv4sw 提取码：e58t</p>
<p>Hinton联合了很多的学者在不断迭代着Capsule的概念和技术，不断地引入新鲜的东西到深度学习中。一方面我觉着我们需要相信大佬的直觉，另一方面我们也不能盲目地追捧，还是要尽量抛开作者光环，去探讨论文研究中是不是拥有着奇思妙想或者醍醐灌顶的东西存在。</p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    yangsenius
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/" title="Stacked Capsule Autoencoders-堆叠的胶囊自编码器">http://senyang-ml.github.io/2020/02/11/stacked-capsule-autoencoders/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/Capsule-Network/" rel="tag"># Capsule Network</a>
          
            <a href="/tags/Unsupervised-Learning/" rel="tag"># Unsupervised Learning</a>
          
            <a href="/tags/PPT/" rel="tag"># PPT</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        
          <div class="wp_rating">
            <div id="wpac-rating"></div>
          </div>
        

        

        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/02/distribution-aware/" rel="next" title="Distribution-Aware Coordinate Representation for Human Pose Estimation">
                <i class="fa fa-chevron-left"></i> Distribution-Aware Coordinate Representation for Human Pose Estimation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/05/24/enhance-hexo-next/" rel="prev" title="Enhance hexo next">
                Enhance hexo next <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">yangsenius</p>
              <p class="site-description motion-element" itemprop="description">Talk is not cheap</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:yangsenius@seu.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#引言"><span class="nav-number">1.</span> <span class="nav-text">1. 引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#概念"><span class="nav-number">2.</span> <span class="nav-text">2. 概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#stacked-capsule-autoencoders-scae"><span class="nav-number">3.</span> <span class="nav-text">3. Stacked Capsule Autoencoders (SCAE)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#scae-pcae-ocae"><span class="nav-number">3.1.</span> <span class="nav-text">SCAE &#x3D; PCAE +OCAE</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#pace"><span class="nav-number">3.1.1.</span> <span class="nav-text">PACE</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#oace"><span class="nav-number">3.1.2.</span> <span class="nav-text">OACE</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#aaai-2020-hinton发表了关于stacked-capsule-autoencoder的演讲"><span class="nav-number">4.</span> <span class="nav-text">4. AAAI 2020 Hinton发表了关于Stacked Capsule AutoEncoder的演讲</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#什么叫偶然性过滤"><span class="nav-number">4.0.1.</span> <span class="nav-text">什么叫偶然性过滤？</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">yangsenius</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  <script type="text/javascript">
  wpac_init = window.wpac_init || [];
  wpac_init.push({widget: 'Rating', id: ,
    el: 'wpac-rating',
    color: 'fc6423'
  });
  (function() {
    if ('WIDGETPACK_LOADED' in window) return;
    WIDGETPACK_LOADED = true;
    var mc = document.createElement('script');
    mc.type = 'text/javascript';
    mc.async = true;
    mc.src = '//embed.widgetpack.com/widget.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
  })();
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


      
  


  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  

</body>
</html>
